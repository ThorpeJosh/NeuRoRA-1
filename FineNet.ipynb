{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "import h5py\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "import hdf5storage\n",
    "\n",
    "#no_measurements = 1200 \n",
    "\n",
    "data_path = './' # os.getcwd() \n",
    "#datasetR = [] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, Data(edge_attr=[183638, 4], edge_index=[2, 183638], o=[183638, 1], x=[577, 4], xt=[577, 4], y=[577, 4])]\n",
      "[1, Data(edge_attr=[37506, 4], edge_index=[2, 37506], o=[37506, 1], x=[227, 4], xt=[227, 4], y=[227, 4])]\n",
      "[2, Data(edge_attr=[77814, 4], edge_index=[2, 77814], o=[77814, 1], x=[677, 4], xt=[677, 4], y=[677, 4])]\n",
      "[3, Data(edge_attr=[40784, 4], edge_index=[2, 40784], o=[40784, 1], x=[341, 4], xt=[341, 4], y=[341, 4])]\n",
      "[4, Data(edge_attr=[99942, 4], edge_index=[2, 99942], o=[99942, 1], x=[450, 4], xt=[450, 4], y=[450, 4])]\n",
      "[5, Data(edge_attr=[37608, 4], edge_index=[2, 37608], o=[37608, 1], x=[332, 4], xt=[332, 4], y=[332, 4])]\n",
      "[6, Data(edge_attr=[191090, 4], edge_index=[2, 191090], o=[191090, 1], x=[553, 4], xt=[553, 4], y=[553, 4])]\n",
      "[7, Data(edge_attr=[46590, 4], edge_index=[2, 46590], o=[46590, 1], x=[338, 4], xt=[338, 4], y=[338, 4])]\n",
      "[8, Data(edge_attr=[126274, 4], edge_index=[2, 126274], o=[126274, 1], x=[1084, 4], xt=[1084, 4], y=[1084, 4])]\n",
      "[9, Data(edge_attr=[43230, 4], edge_index=[2, 43230], o=[43230, 1], x=[472, 4], xt=[472, 4], y=[472, 4])]\n",
      "[10, Data(edge_attr=[1292958, 4], edge_index=[2, 1292958], o=[1292958, 1], x=[5058, 4], xt=[5058, 4], y=[5058, 4])]\n",
      "[11, Data(edge_attr=[46706, 4], edge_index=[2, 46706], o=[46706, 1], x=[789, 4], xt=[789, 4], y=[789, 4])]\n",
      "[12, Data(edge_attr=[193406, 4], edge_index=[2, 193406], o=[193406, 1], x=[836, 4], xt=[836, 4], y=[836, 4])]\n",
      "[13, Data(edge_attr=[52168, 4], edge_index=[2, 52168], o=[52168, 1], x=[437, 4], xt=[437, 4], y=[437, 4])]\n",
      "[14, Data(edge_attr=[22752, 4], edge_index=[2, 22752], o=[22752, 1], x=[463, 4], xt=[463, 4], y=[463, 4])]\n",
      "[15, Data(edge_attr=[128540, 4], edge_index=[2, 128540], o=[128540, 1], x=[715, 4], xt=[715, 4], y=[715, 4])]\n"
     ]
    }
   ],
   "source": [
    "no_measurements = 16\n",
    "datasetTrain = [] \n",
    "filename = data_path+'data/bootstrapped_train_9.h5' \n",
    "for item in range(no_measurements): \n",
    "    x = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/x', filename=filename, options=None), dtype=torch.float)\n",
    "    xt = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/xt', filename=filename, options=None), dtype=torch.float)\n",
    "    o = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/o', filename=filename, options=None), dtype=torch.float)\n",
    " #   onode = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/onode', filename=filename, options=None), dtype=torch.float)\n",
    " #   omarker = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/omarker', filename=filename, options=None), dtype=torch.float)\n",
    "    edge_index = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/edge_index', filename=filename, options=None), dtype=torch.long)\n",
    "    edge_attr = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/edge_feature', filename=filename, options=None), dtype=torch.float)\n",
    "    y = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/y', filename=filename, options=None), dtype=torch.float)\n",
    "    datasetTrain.append(Data(x=x, xt=xt, o=o, y=y, edge_index=edge_index.t().contiguous(), edge_attr=edge_attr)) \n",
    "    print([item, datasetTrain[item]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, Data(edge_attr=[535814, 4], edge_index=[2, 535814], o=[1, 535814], x=[2152, 4], xt=[2152, 4], y=[2152, 4])]\n"
     ]
    }
   ],
   "source": [
    "no_measurements = 1 \n",
    "datasetTest = [] \n",
    "\n",
    "filename = data_path+'data/bootstrapped_test_9.h5' \n",
    "#filename = data_path+'data/gt_graph_random_large_outliers_real_updated.h5' \n",
    "for item in range(no_measurements): \n",
    "    x = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/x', filename=filename, options=None), dtype=torch.float)\n",
    "    xt = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/xt', filename=filename, options=None), dtype=torch.float)\n",
    "    o = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/o', filename=filename, options=None), dtype=torch.float)\n",
    " #   onode = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/onode', filename=filename, options=None), dtype=torch.float)\n",
    " #   omarker = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/omarker', filename=filename, options=None), dtype=torch.float)\n",
    "    edge_index = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/edge_index', filename=filename, options=None), dtype=torch.long)\n",
    "    edge_attr = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/edge_feature', filename=filename, options=None), dtype=torch.float)\n",
    "    y = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/y', filename=filename, options=None), dtype=torch.float)\n",
    "    datasetTest.append(Data(x=x, xt=xt, o=o.t(), y=y, edge_index=edge_index.t().contiguous(), edge_attr=edge_attr)) \n",
    "    print([item, datasetTest[item]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qmul(q, r):\n",
    "    \"\"\"\n",
    "    Multiply quaternion(s) q with quaternion(s) r.\n",
    "    \"\"\"\n",
    "    assert q.shape[-1] == 4\n",
    "    assert r.shape[-1] == 4\n",
    "\n",
    "    original_shape = q.shape\n",
    "\n",
    "    # Compute outer product\n",
    "    terms = torch.bmm(r.view(-1, 4, 1), q.view(-1, 1, 4))\n",
    "\n",
    "    w = terms[:, 0, 0] - terms[:, 1, 1] - terms[:, 2, 2] - terms[:, 3, 3]\n",
    "    x = terms[:, 0, 1] + terms[:, 1, 0] - terms[:, 2, 3] + terms[:, 3, 2]\n",
    "    y = terms[:, 0, 2] + terms[:, 1, 3] + terms[:, 2, 0] - terms[:, 3, 1]\n",
    "    z = terms[:, 0, 3] - terms[:, 1, 2] + terms[:, 2, 1] + terms[:, 3, 0]\n",
    "    return torch.stack((w, x, y, z), dim=1).view(original_shape)\n",
    "\n",
    "def inv_q(q):\n",
    "    \"\"\"\n",
    "    Inverse quaternion(s) q .\n",
    "    \"\"\"\n",
    "    assert q.shape[-1] == 4\n",
    "    original_shape = q.shape\n",
    "    return torch.stack((q[:, 0], -q[:, 1], -q[:, 2], -q[:, 3]), dim=1).view(original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential as Seq, Linear, ReLU, BatchNorm1d as BN, Dropout\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class EdgeConvRot(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_channels, out_channels):\n",
    "        super(EdgeConvRot, self).__init__(aggr='mean', flow=\"target_to_source\") #  \"Max\" aggregation.\n",
    "        self.mlp = Seq(Linear(2*in_channels+edge_channels, out_channels),\n",
    "               ReLU(),\n",
    "               Linear(out_channels, out_channels))\n",
    "            \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr): \n",
    "        W = torch.cat([torch.cat([x_i, x_j], dim=1), edge_attr], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
    "        W = self.mlp(W) \n",
    "        return W\n",
    "            \n",
    "    def propagate(self, edge_index, size, x, edge_attr):    \n",
    "        row, col = edge_index\n",
    "        x_i = x[row]\n",
    "        x_j = x[col]\n",
    "        i, j = (0, 1) if self.flow == 'target_to_source' else (1, 0) \n",
    "        edge_out = self.message(x_i, x_j, edge_attr)\n",
    "        out = scatter_(self.aggr, edge_out, edge_index[i], dim_size=size[i])\n",
    "        return out, edge_out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import scatter_\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "def node_model(x, batch):\n",
    "   # print(batch.shape)\n",
    "    out, inverse_indices = torch.unique_consecutive(batch, return_inverse=True)\n",
    "    quat_vals = x[inverse_indices] \n",
    "    q_ij = qmul(x, inv_q(quat_vals[batch]))  \n",
    "    return q_ij \n",
    "\n",
    "def edge_model(x, edge_index):\n",
    "    row, col = edge_index\n",
    "    q_ij = qmul(x[col], inv_q(x[row]))  \n",
    "    return q_ij \n",
    "\n",
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Linear(channels[i - 1], channels[i]), ReLU())\n",
    "        for i in range(1, len(channels))\n",
    "    ])\n",
    "class EdgePred(torch.nn.Module):\n",
    "    def __init__(self, in_channels, edge_channels):\n",
    "        super(EdgePred, self).__init__()\n",
    "        self.mlp = Seq(Linear(2*in_channels+edge_channels, 8),\n",
    "                       ReLU(),\n",
    "                       Linear(8, 1)) \n",
    "    def forward(self, xn, edge_index, edge_attr): \n",
    "        row, col = edge_index\n",
    "        xn = torch.cat([xn[row], xn[col], edge_attr], dim=1)\n",
    "        xn = self.mlp(xn) \n",
    "        return torch.sigmoid(xn) \n",
    "    \n",
    "class GlobalSAModule(torch.nn.Module):\n",
    "    def __init__(self, nn1, nn2):\n",
    "        super(GlobalSAModule, self).__init__()\n",
    "        self.nn1 = nn1\n",
    "        self.nn2 = nn2\n",
    "\n",
    "    def forward(self, x, batch): \n",
    "        xn = self.nn1(x)\n",
    "      #  xn = F._max_pool1d(xn, x.size(1))\n",
    "       # xn = scatter_('mean', xn, batch)\n",
    "       # xn = xn[batch]  \n",
    "        xn = torch.cat([xn, x], dim=1) \n",
    "     #   print(xn.shape)\n",
    "      #  x = xn.unsqueeze(0).repeat(x.size(0), 1, 1) \n",
    "      #  batch = torch.arange(x.size(0), device=batch.device)\n",
    "        return self.nn2(xn)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_attr(x, edge_index, edge_attr):\n",
    "    row, col = edge_index\n",
    "    x_i = x[row]\n",
    "    x_j = inv_q(x[col])\n",
    " #   print(x_i.shape)\n",
    "  #  print(x_j.shape)\n",
    "   # print(edge_attr.shape) \n",
    "    W=qmul(edge_attr, x_i) \n",
    "    W=qmul(x_j, W) \n",
    "    return W \n",
    "\n",
    "\n",
    "\n",
    "def smooth_l1_loss(input, beta=0.05, size_average=True):\n",
    "    \"\"\"\n",
    "    very similar to the smooth_l1_loss from pytorch, but with\n",
    "    the extra beta parameter\n",
    "    \"\"\"\n",
    "    nn0 = torch.min(1.0 - input[:, 0], 1.0 + input[:, 0])     \n",
    "    \n",
    "    n = torch.abs(nn0) + torch.sum(torch.abs(input[:, 1:]), dim=1)      \n",
    " #   cond = n < 5*beta\n",
    "  #  n = torch.where(cond, n, 0*n)\n",
    "    cond = n < beta\n",
    "    loss = torch.where(cond, 0.5 * n ** 2 / beta, n - 0.5 * beta)\n",
    "    if size_average:\n",
    "        return loss.mean()\n",
    "    return loss.sum()\n",
    "\n",
    "def my_smooth_l1_loss(input, beta, alpha=0.05):\n",
    "    \"\"\"\n",
    "    very similar to the smooth_l1_loss from pytorch, but with\n",
    "    the extra beta parameter\n",
    "    \"\"\"\n",
    "    nn0 = torch.min(1.0 - input[:, 0], 1.0 + input[:, 0]) \n",
    "    nn = torch.abs(nn0) + torch.sum(torch.abs(input[:, 1:]), dim=1) \n",
    "    beta = torch.squeeze(beta) \n",
    "    nn = torch.mul(nn, beta) \n",
    "   # print([nn.shape, beta.shape])\n",
    "   # nn = nn + alpha*(torch.ones(beta.shape, dtype=torch.float, device=input.device) - beta) \n",
    "    cond = nn < alpha\n",
    "    loss = torch.where(cond, 0.5 * nn ** 2 / alpha, nn - 0.5 * alpha)\n",
    "    return loss.mean()\n",
    "\n",
    "def my_smooth_l1_loss_new(input, beta, edge_index, size, alpha=0.05):\n",
    "    \"\"\"\n",
    "    very similar to the smooth_l1_loss from pytorch, but with\n",
    "    the extra beta parameter\n",
    "    \"\"\"\n",
    "    nn0 = torch.min(1.0 - input[:, 0], 1.0 + input[:, 0]) \n",
    "    nn = torch.abs(nn0) + torch.sum(torch.abs(input[:, 1:]), dim=1) \n",
    "    beta = torch.squeeze(beta) \n",
    "    nn = torch.mul(nn, beta) \n",
    "    \n",
    "    cond = nn < alpha\n",
    "    loss = torch.where(cond, 0.5 * nn ** 2 / alpha, nn - 0.5 * alpha)   \n",
    "    loss = scatter_('mean', loss, edge_index[0], dim_size=size(0)) \n",
    "        \n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(Net, self).__init__() \n",
    "        self.no_features = 32   # More features for large dataset \n",
    "        self.conv1 = EdgeConvRot(4, 4, self.no_features) \n",
    "        self.conv2 = EdgeConvRot(self.no_features, self.no_features+4, self.no_features)  \n",
    "        self.conv3 = EdgeConvRot(2*self.no_features, 2*self.no_features, self.no_features) \n",
    "        self.conv4 = EdgeConvRot(2*self.no_features, 2*self.no_features, self.no_features) \n",
    "\n",
    "        self.lin1 = Linear(self.no_features, 4) \n",
    "        \n",
    "        self.m = torch.nn.Sigmoid() \n",
    "    def forward(self, data):\n",
    "        x_org, edge_index, edge_attr, batch, beta = data.x, data.edge_index, data.edge_attr, data.batch, data.o  \n",
    "        \n",
    "        edge_attr_mod = update_attr(x_org, edge_index, edge_attr[:, :4])\n",
    "        x1, edge_x1 = self.conv1(x_org, edge_index,edge_attr_mod)\n",
    "        x1 = F.relu(x1)\n",
    "        edge_x1 = F.relu(edge_x1)\n",
    "        \n",
    "        x2, edge_x2 = self.conv2(x1, edge_index, torch.cat([edge_attr_mod, edge_x1], dim=1))\n",
    "        x2 = F.relu(x2)\n",
    "        edge_x2 = F.relu(edge_x2)\n",
    "\n",
    "        x3, edge_x3 = self.conv3(torch.cat([x2, x1], dim=1), edge_index, torch.cat([edge_x2, edge_x1], dim=1))\n",
    "        x3 = F.relu(x3)\n",
    "        edge_x3 = F.relu(edge_x3)\n",
    "        \n",
    "        x4, edge_x4 = self.conv4(torch.cat([x3, x2], dim=1), edge_index, torch.cat([edge_x3, edge_x2], dim=1))\n",
    "        x4 = F.relu(x4)\n",
    "        \n",
    "        x = self.lin1(x4) \n",
    "       \n",
    "        x = x + x_org #qmul(x, x_org) \n",
    "        x = F.normalize(x, p=2, dim=1) \n",
    "        \n",
    "   #     loss1 = inv_q(edge_model(data.y, edge_index)) - edge_model(x, edge_index) \n",
    "        loss1 = qmul(inv_q(edge_model(data.y, edge_index)), edge_model(x, edge_index)) \n",
    "        loss1 = F.normalize(loss1, p=2, dim=1) \n",
    "#        loss1 = qmul(inv_q(edge_attr[:, :4]), edge_model(x, edge_index)) \n",
    "        loss1 = my_smooth_l1_loss_new(loss1[:, 0:], beta, edge_index, x_org.size)\n",
    "        return x, loss1, beta   # node_model(x, batch),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'checkpoint/finenet_9.pth' \n",
    "import time\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "training_exmpl = 0.8\n",
    "model = Net().to(device) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "#checkpoint = torch.load(PATH)\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict']) \n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, '0.122196', '61.83', '33.48', '0.726958'] 1.449\n",
      "[2, '0.098784', '61.20', '30.28', '0.579243'] 3.710\n",
      "[4, '0.093762', '58.82', '26.68', '0.532862'] 5.997\n",
      "[6, '0.089965', '57.06', '23.98', '0.493109'] 8.282\n",
      "[8, '0.087147', '55.50', '21.53', '0.461195'] 10.538\n",
      "[10, '0.110305', '52.83', '19.72', '0.565737'] 12.981\n",
      "[12, '0.082976', '52.79', '17.45', '0.403192'] 15.223\n",
      "[14, '0.081247', '51.41', '15.40', '0.369531'] 17.481\n",
      "[16, '0.079695', '49.91', '13.38', '0.334547'] 19.812\n",
      "[18, '0.078124', '48.65', '11.85', '0.307270'] 22.053\n",
      "[20, '0.105208', '46.81', '11.88', '0.468718'] 24.467\n",
      "[22, '0.076075', '48.10', '11.28', '0.295941'] 26.768\n",
      "[24, '0.075517', '48.08', '11.33', '0.295234'] 29.028\n",
      "[26, '0.075176', '48.10', '11.31', '0.295380'] 31.277\n",
      "[28, '0.074939', '48.13', '11.32', '0.295520'] 33.544\n",
      "[30, '0.105342', '46.84', '12.12', '0.474749'] 36.026\n",
      "[32, '0.074674', '48.15', '11.29', '0.295858'] 38.256\n",
      "[34, '0.074633', '48.14', '11.33', '0.295610'] 40.495\n",
      "[36, '0.074548', '48.15', '11.34', '0.295691'] 42.722\n",
      "[38, '0.074509', '48.19', '11.44', '0.296123'] 44.973\n",
      "[40, '0.105241', '46.85', '12.11', '0.475508'] 47.401\n",
      "[42, '0.074397', '48.16', '11.36', '0.295800'] 49.618\n",
      "[44, '0.074355', '48.15', '11.34', '0.295580'] 51.855\n",
      "[46, '0.074304', '48.15', '11.34', '0.295547'] 54.168\n",
      "[48, '0.074244', '48.14', '11.36', '0.295594'] 56.385\n",
      "[50, '0.105029', '46.85', '12.11', '0.475011'] 58.824\n",
      "[52, '0.074137', '48.13', '11.34', '0.295291'] 61.098\n",
      "[54, '0.074078', '48.13', '11.24', '0.295435'] 63.384\n",
      "[56, '0.074029', '48.14', '11.37', '0.295294'] 65.626\n",
      "[58, '0.073948', '48.13', '11.30', '0.295324'] 67.940\n",
      "[60, '0.104563', '46.82', '12.05', '0.473402'] 70.433\n",
      "[62, '0.073771', '48.12', '11.29', '0.295086'] 72.787\n",
      "[64, '0.073719', '48.12', '11.27', '0.295564'] 75.058\n",
      "[66, '0.073584', '48.10', '11.30', '0.294628'] 77.271\n",
      "[68, '0.073459', '48.08', '11.22', '0.294570'] 79.576\n",
      "[70, '0.103933', '46.78', '11.99', '0.472191'] 81.993\n",
      "[72, '0.073226', '48.06', '11.23', '0.294316'] 84.236\n",
      "[74, '0.073111', '48.06', '11.21', '0.294268'] 86.457\n",
      "[76, '0.072938', '48.08', '11.27', '0.294230'] 88.719\n",
      "[78, '0.072766', '48.03', '11.18', '0.293666'] 90.991\n",
      "[80, '0.102837', '46.69', '11.83', '0.469536'] 93.425\n",
      "[82, '0.072325', '48.01', '11.16', '0.293199'] 95.673\n",
      "[84, '0.072017', '48.00', '11.21', '0.292912'] 97.978\n",
      "[86, '0.071712', '47.97', '11.17', '0.292437'] 100.224\n",
      "[88, '0.071313', '47.98', '11.12', '0.292429'] 102.439\n",
      "[90, '0.100483', '46.57', '11.76', '0.464082'] 104.966\n",
      "[92, '0.070459', '47.94', '11.05', '0.291599'] 107.163\n",
      "[94, '0.070153', '47.99', '11.13', '0.291936'] 109.486\n",
      "[96, '0.069511', '47.91', '10.92', '0.291080'] 111.787\n",
      "[98, '0.069077', '47.90', '10.95', '0.290515'] 114.027\n",
      "[100, '0.097119', '46.45', '11.56', '0.457381'] 116.483\n",
      "[102, '0.067910', '47.87', '10.93', '0.289856'] 118.715\n",
      "[104, '0.067188', '47.84', '10.88', '0.289126'] 120.944\n",
      "[106, '0.066580', '47.85', '10.93', '0.288985'] 123.216\n",
      "[108, '0.065975', '47.81', '10.79', '0.288138'] 125.544\n",
      "[110, '0.093060', '46.30', '11.41', '0.449839'] 128.010\n",
      "[112, '0.065089', '47.79', '10.83', '0.287700'] 130.234\n",
      "[114, '0.064554', '47.90', '10.78', '0.289791'] 132.515\n",
      "[116, '0.064154', '47.82', '10.74', '0.288505'] 134.773\n",
      "[118, '0.063836', '47.77', '10.72', '0.287816'] 137.007\n",
      "[120, '0.090512', '46.25', '11.23', '0.445340'] 139.480\n",
      "[122, '0.063347', '47.92', '11.08', '0.291165'] 141.761\n",
      "[124, '0.062695', '47.73', '10.56', '0.286917'] 143.996\n",
      "[126, '0.062460', '47.73', '10.57', '0.286998'] 146.222\n",
      "[128, '0.062088', '47.72', '10.49', '0.286478'] 148.469\n",
      "[130, '0.089102', '46.35', '11.04', '0.446663'] 150.916\n",
      "[132, '0.061546', '47.86', '10.64', '0.288596'] 153.156\n",
      "[134, '0.061295', '47.70', '10.45', '0.286519'] 155.394\n",
      "[136, '0.061122', '47.77', '10.55', '0.287209'] 157.661\n",
      "[138, '0.060857', '47.72', '10.44', '0.286484'] 159.910\n",
      "[140, '0.087987', '46.08', '11.05', '0.443096'] 162.341\n",
      "[142, '0.060552', '47.64', '10.38', '0.285427'] 164.584\n",
      "[144, '0.060398', '47.61', '10.41', '0.285403'] 166.838\n",
      "[146, '0.060168', '47.61', '10.43', '0.285849'] 169.107\n",
      "[148, '0.060034', '47.63', '10.39', '0.285904'] 171.395\n",
      "[150, '0.087449', '46.11', '10.85', '0.445375'] 173.713\n",
      "[152, '0.059744', '47.63', '10.25', '0.285046'] 175.952\n",
      "[154, '0.059671', '47.55', '10.37', '0.284807'] 178.186\n",
      "[156, '0.059479', '47.64', '10.20', '0.285213'] 180.433\n",
      "[158, '0.059358', '47.61', '10.23', '0.284783'] 182.703\n",
      "[160, '0.086835', '45.96', '10.83', '0.441003'] 185.169\n",
      "[162, '0.059126', '47.53', '10.27', '0.283932'] 187.403\n",
      "[164, '0.059072', '47.61', '10.28', '0.285595'] 189.633\n",
      "[166, '0.058915', '47.60', '10.30', '0.284936'] 191.817\n",
      "[168, '0.058836', '47.58', '10.26', '0.285062'] 194.054\n",
      "[170, '0.086617', '45.97', '10.75', '0.441250'] 196.534\n",
      "[172, '0.058587', '47.58', '10.22', '0.284475'] 198.808\n",
      "[174, '0.058594', '47.62', '10.08', '0.285039'] 201.025\n",
      "[176, '0.058387', '47.69', '10.08', '0.285655'] 203.201\n",
      "[178, '0.058293', '47.49', '10.23', '0.283607'] 205.440\n",
      "[180, '0.086211', '45.97', '10.71', '0.440213'] 207.873\n",
      "[182, '0.058190', '47.58', '10.29', '0.285199'] 210.105\n",
      "[184, '0.057978', '47.49', '10.32', '0.283503'] 212.317\n",
      "[186, '0.057933', '47.58', '10.34', '0.285112'] 214.494\n",
      "[188, '0.057819', '47.58', '10.28', '0.284787'] 216.770\n",
      "[190, '0.086046', '45.96', '10.75', '0.440705'] 219.308\n",
      "[192, '0.057660', '47.49', '10.17', '0.284014'] 221.542\n",
      "[194, '0.057500', '47.51', '10.14', '0.283756'] 223.801\n",
      "[196, '0.057403', '47.53', '10.03', '0.283643'] 226.003\n",
      "[198, '0.057409', '47.66', '10.45', '0.285847'] 228.264\n",
      "[200, '0.085639', '45.91', '10.75', '0.440252'] 230.714\n",
      "[202, '0.057204', '47.50', '10.24', '0.283695'] 232.974\n",
      "[204, '0.057042', '47.49', '10.07', '0.283092'] 235.237\n",
      "[206, '0.056942', '47.43', '10.11', '0.282470'] 237.466\n",
      "[208, '0.056895', '47.59', '10.16', '0.284687'] 239.696\n",
      "[210, '0.085352', '45.96', '10.73', '0.441543'] 242.165\n",
      "[212, '0.056748', '47.51', '10.28', '0.284084'] 244.399\n",
      "[214, '0.056541', '47.46', '10.00', '0.283206'] 246.678\n",
      "[216, '0.056431', '47.49', '10.01', '0.282914'] 248.963\n",
      "[218, '0.056313', '47.48', '10.02', '0.282958'] 251.216\n",
      "[220, '0.084759', '45.85', '10.61', '0.439116'] 253.714\n",
      "[222, '0.056143', '47.47', '10.06', '0.282807'] 255.954\n",
      "[224, '0.055960', '47.42', '10.10', '0.282151'] 258.222\n",
      "[226, '0.055952', '47.48', '10.06', '0.282902'] 260.526\n",
      "[228, '0.055781', '47.45', '10.01', '0.282600'] 262.782\n",
      "[230, '0.084285', '45.82', '10.61', '0.438513'] 265.265\n",
      "[232, '0.055545', '47.46', '10.04', '0.282591'] 267.607\n",
      "[234, '0.055448', '47.44', '9.96', '0.282196'] 269.837\n",
      "[236, '0.055297', '47.41', '9.98', '0.281871'] 272.083\n",
      "[238, '0.055228', '47.42', '9.98', '0.281832'] 274.385\n",
      "[240, '0.084069', '45.82', '10.49', '0.443656'] 276.803\n",
      "[242, '0.054981', '47.59', '10.21', '0.284466'] 279.027\n",
      "[244, '0.054820', '47.42', '9.81', '0.281463'] 281.296\n",
      "[246, '0.054682', '47.39', '9.94', '0.281677'] 283.516\n",
      "[248, '0.054633', '47.39', '9.91', '0.281184'] 285.759\n",
      "[250, '0.083367', '45.93', '10.50', '0.439200'] 288.242\n",
      "[252, '0.054352', '47.42', '9.98', '0.282176'] 290.496\n",
      "[254, '0.054299', '47.43', '10.03', '0.282409'] 292.657\n",
      "[256, '0.054054', '47.41', '9.90', '0.281425'] 294.847\n",
      "[258, '0.053972', '47.42', '9.96', '0.281878'] 297.090\n",
      "[260, '0.082463', '45.79', '10.53', '0.437223'] 299.566\n",
      "[262, '0.053713', '47.35', '9.80', '0.280737'] 301.781\n",
      "[264, '0.053565', '47.34', '9.85', '0.280439'] 304.009\n",
      "[266, '0.053487', '47.36', '9.79', '0.280776'] 306.256\n",
      "[268, '0.053299', '47.36', '9.73', '0.280413'] 308.544\n",
      "[270, '0.081629', '45.78', '10.39', '0.436898'] 310.975\n",
      "[272, '0.053046', '47.32', '9.74', '0.279746'] 313.184\n",
      "[274, '0.052984', '47.38', '9.87', '0.280754'] 315.458\n",
      "[276, '0.052888', '47.41', '9.70', '0.281535'] 317.691\n",
      "[278, '0.052690', '47.28', '9.74', '0.279218'] 319.926\n",
      "[280, '0.080842', '45.74', '10.38', '0.435956'] 322.382\n",
      "[282, '0.052567', '47.31', '9.75', '0.279504'] 324.593\n",
      "[284, '0.052411', '47.20', '9.63', '0.278082'] 326.869\n",
      "[286, '0.052298', '47.38', '9.92', '0.281234'] 329.111\n",
      "[288, '0.052188', '47.31', '9.80', '0.279456'] 331.439\n",
      "[290, '0.080359', '45.72', '10.27', '0.435141'] 333.866\n",
      "[292, '0.051928', '47.52', '9.68', '0.282299'] 336.149\n",
      "[294, '0.051900', '47.30', '9.82', '0.279686'] 338.423\n",
      "[296, '0.051925', '47.45', '9.80', '0.283668'] 340.663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[298, '0.051672', '47.29', '9.59', '0.279395'] 342.906\n",
      "[300, '0.079686', '45.70', '10.28', '0.433278'] 345.366\n",
      "[302, '0.051469', '47.21', '9.60', '0.277975'] 347.629\n",
      "[304, '0.051417', '47.31', '9.58', '0.279773'] 349.862\n",
      "[306, '0.051328', '47.23', '9.58', '0.278295'] 352.121\n",
      "[308, '0.051403', '47.30', '9.66', '0.279696'] 354.402\n",
      "[310, '0.079050', '45.71', '10.28', '0.432170'] 356.814\n",
      "[312, '0.051107', '47.22', '9.57', '0.278507'] 359.030\n",
      "[314, '0.051054', '47.22', '9.78', '0.278264'] 361.197\n",
      "[316, '0.051018', '47.21', '9.50', '0.277941'] 363.467\n",
      "[318, '0.050938', '47.27', '9.63', '0.278631'] 365.693\n",
      "[320, '0.078709', '45.64', '10.16', '0.432233'] 367.999\n",
      "[322, '0.050765', '47.19', '9.48', '0.277256'] 370.257\n",
      "[324, '0.050737', '47.23', '9.59', '0.278192'] 372.473\n",
      "[326, '0.050828', '47.06', '9.34', '0.276825'] 374.727\n",
      "[328, '0.050756', '47.42', '9.58', '0.280361'] 377.025\n",
      "[330, '0.078548', '45.66', '10.02', '0.431881'] 379.476\n",
      "[332, '0.050668', '47.27', '9.58', '0.278406'] 381.636\n",
      "[334, '0.050592', '47.20', '9.66', '0.278459'] 383.867\n",
      "[336, '0.050599', '47.33', '9.59', '0.280327'] 386.092\n",
      "[338, '0.050459', '47.22', '9.55', '0.277963'] 388.316\n",
      "[340, '0.078293', '45.66', '10.07', '0.433670'] 390.800\n",
      "[342, '0.050384', '47.25', '9.58', '0.278323'] 393.065\n",
      "[344, '0.050364', '47.13', '9.54', '0.276513'] 395.304\n",
      "[346, '0.050307', '47.16', '9.52', '0.277265'] 397.540\n",
      "[348, '0.050340', '47.11', '9.39', '0.276824'] 399.812\n",
      "[350, '0.077723', '45.51', '10.12', '0.431743'] 402.277\n",
      "[352, '0.050195', '47.21', '9.51', '0.278107'] 404.557\n",
      "[354, '0.050161', '47.16', '9.50', '0.276890'] 406.764\n",
      "[356, '0.050101', '47.18', '9.36', '0.276709'] 409.034\n",
      "[358, '0.050057', '47.09', '9.49', '0.276225'] 411.285\n",
      "[360, '0.077511', '45.53', '10.16', '0.426712'] 413.690\n",
      "[362, '0.050069', '47.24', '9.38', '0.278433'] 415.974\n",
      "[364, '0.050010', '47.14', '9.36', '0.276372'] 418.219\n",
      "[366, '0.050020', '47.14', '9.23', '0.276226'] 420.533\n",
      "[368, '0.049990', '47.16', '9.25', '0.276187'] 422.751\n",
      "[370, '0.077434', '45.51', '10.04', '0.429322'] 425.237\n",
      "[372, '0.049933', '47.09', '9.51', '0.276612'] 427.476\n",
      "[374, '0.049933', '47.10', '9.51', '0.276159'] 429.746\n",
      "[376, '0.049818', '47.17', '9.32', '0.276471'] 431.980\n",
      "[378, '0.049826', '47.06', '9.34', '0.275795'] 434.253\n",
      "[380, '0.077198', '45.45', '9.93', '0.427137'] 436.772\n",
      "[382, '0.049781', '47.26', '9.27', '0.277266'] 438.989\n",
      "[384, '0.049775', '47.19', '9.28', '0.278115'] 441.259\n",
      "[386, '0.049721', '47.07', '9.41', '0.276254'] 443.522\n",
      "[388, '0.049692', '47.02', '9.40', '0.275241'] 445.754\n",
      "[390, '0.076972', '45.48', '9.98', '0.427093'] 448.235\n",
      "[392, '0.049589', '47.10', '9.38', '0.275974'] 450.437\n",
      "[394, '0.049626', '47.03', '9.43', '0.275004'] 452.678\n",
      "[396, '0.049587', '47.06', '9.45', '0.275414'] 454.907\n",
      "[398, '0.049628', '47.00', '9.42', '0.275315'] 457.208\n",
      "[400, '0.077183', '45.47', '9.81', '0.427548'] 459.709\n",
      "[402, '0.049519', '47.16', '9.39', '0.276877'] 461.949\n",
      "[404, '0.049479', '47.37', '9.29', '0.278811'] 464.185\n",
      "[406, '0.049459', '46.99', '9.30', '0.274601'] 466.497\n",
      "[408, '0.049534', '47.07', '9.53', '0.275666'] 468.772\n",
      "[410, '0.077018', '45.39', '9.85', '0.430346'] 471.193\n",
      "[412, '0.049357', '47.06', '9.20', '0.275244'] 473.457\n",
      "[414, '0.049350', '47.09', '9.36', '0.275644'] 475.630\n",
      "[416, '0.049345', '47.08', '9.23', '0.275293'] 477.818\n",
      "[418, '0.049273', '47.10', '9.19', '0.275979'] 480.109\n",
      "[420, '0.076698', '45.48', '9.99', '0.427562'] 482.606\n",
      "[422, '0.049299', '47.12', '9.38', '0.276475'] 484.921\n",
      "[424, '0.049314', '47.01', '9.26', '0.275680'] 487.179\n",
      "[426, '0.049259', '46.97', '9.15', '0.275030'] 489.372\n",
      "[428, '0.049220', '47.00', '9.30', '0.274616'] 491.656\n",
      "[430, '0.076463', '45.35', '9.88', '0.424464'] 494.046\n",
      "[432, '0.049094', '46.98', '9.15', '0.274446'] 496.277\n",
      "[434, '0.049111', '46.98', '9.27', '0.274256'] 498.511\n",
      "[436, '0.049125', '46.98', '9.28', '0.275111'] 500.778\n",
      "[438, '0.048994', '47.04', '9.33', '0.275614'] 503.011\n",
      "[440, '0.076265', '45.38', '9.93', '0.423403'] 505.428\n",
      "[442, '0.048936', '47.21', '9.28', '0.276849'] 507.648\n",
      "[444, '0.048953', '46.97', '9.30', '0.274418'] 509.909\n",
      "[446, '0.048921', '46.95', '9.15', '0.274023'] 512.159\n",
      "[448, '0.048854', '46.94', '9.20', '0.274043'] 514.379\n",
      "[450, '0.076189', '45.24', '9.82', '0.421934'] 516.858\n",
      "[452, '0.048833', '47.01', '9.18', '0.274357'] 519.103\n",
      "[454, '0.048818', '47.10', '9.19', '0.275269'] 521.340\n",
      "[456, '0.048817', '47.03', '9.30', '0.275909'] 523.662\n",
      "[458, '0.048888', '47.05', '9.24', '0.275789'] 525.883\n",
      "[460, '0.076020', '45.42', '9.96', '0.421925'] 528.344\n",
      "[462, '0.048805', '46.96', '9.04', '0.274109'] 530.608\n",
      "[464, '0.048767', '47.08', '9.19', '0.276258'] 532.865\n",
      "[466, '0.048639', '46.90', '9.13', '0.273569'] 535.090\n",
      "[468, '0.048583', '46.95', '9.33', '0.274401'] 537.306\n",
      "[470, '0.076070', '45.40', '9.87', '0.423800'] 539.737\n",
      "[472, '0.048671', '46.87', '9.24', '0.273199'] 541.910\n",
      "[474, '0.048608', '46.97', '9.19', '0.275867'] 544.139\n",
      "[476, '0.048527', '46.98', '9.15', '0.274528'] 546.445\n",
      "[478, '0.048434', '46.91', '8.90', '0.273580'] 548.684\n",
      "[480, '0.075916', '45.33', '9.75', '0.425265'] 551.109\n",
      "[482, '0.048383', '46.87', '9.03', '0.272519'] 553.430\n",
      "[484, '0.048331', '46.89', '9.09', '0.273124'] 555.650\n",
      "[486, '0.048404', '46.93', '9.06', '0.273951'] 557.918\n",
      "[488, '0.048227', '46.92', '9.27', '0.272976'] 560.185\n",
      "[490, '0.075534', '45.25', '9.65', '0.419601'] 562.579\n",
      "[492, '0.048322', '46.99', '9.20', '0.273989'] 564.838\n",
      "[494, '0.048287', '47.08', '9.02', '0.275201'] 567.111\n",
      "[496, '0.048153', '47.01', '9.16', '0.274067'] 569.308\n",
      "[498, '0.048165', '47.07', '9.16', '0.276075'] 571.627\n",
      "[500, '0.075368', '45.20', '9.72', '0.422043'] 574.087\n",
      "[502, '0.048238', '46.84', '9.50', '0.273777'] 576.327\n",
      "[504, '0.048083', '46.85', '9.16', '0.272930'] 578.611\n",
      "[506, '0.048055', '46.90', '9.18', '0.274125'] 580.785\n",
      "[508, '0.047907', '46.91', '9.16', '0.272956'] 583.024\n",
      "[510, '0.075191', '45.20', '9.76', '0.421741'] 585.408\n",
      "[512, '0.047812', '46.88', '9.03', '0.272697'] 587.621\n",
      "[514, '0.047812', '46.82', '9.01', '0.272448'] 589.884\n",
      "[516, '0.047812', '47.12', '9.29', '0.276698'] 592.118\n",
      "[518, '0.047695', '46.84', '9.06', '0.271959'] 594.300\n",
      "[520, '0.075319', '45.24', '9.73', '0.426113'] 596.713\n",
      "[522, '0.047642', '46.79', '9.14', '0.272108'] 598.995\n",
      "[524, '0.047629', '46.76', '8.98', '0.271528'] 601.262\n",
      "[526, '0.047661', '46.80', '9.19', '0.272495'] 603.582\n",
      "[528, '0.047609', '46.99', '9.03', '0.274980'] 605.815\n",
      "[530, '0.075814', '45.54', '10.29', '0.433755'] 608.211\n",
      "[532, '0.047397', '46.83', '9.04', '0.272289'] 610.362\n",
      "[534, '0.047390', '46.86', '9.33', '0.273366'] 612.639\n",
      "[536, '0.047412', '46.72', '8.91', '0.271074'] 614.940\n",
      "[538, '0.047335', '46.91', '8.93', '0.273628'] 617.208\n",
      "[540, '0.074945', '45.21', '9.71', '0.422982'] 619.730\n",
      "[542, '0.047292', '46.77', '8.88', '0.271834'] 621.984\n",
      "[544, '0.047264', '46.81', '8.96', '0.272478'] 624.237\n",
      "[546, '0.047160', '46.67', '8.96', '0.270912'] 626.503\n",
      "[548, '0.047149', '46.72', '8.84', '0.270901'] 628.752\n",
      "[550, '0.074755', '45.20', '9.60', '0.419751'] 631.119\n",
      "[552, '0.046961', '46.80', '8.96', '0.271679'] 633.378\n",
      "[554, '0.046978', '46.92', '8.97', '0.274186'] 635.598\n",
      "[556, '0.046820', '46.74', '8.91', '0.271649'] 637.855\n",
      "[558, '0.046976', '46.77', '9.09', '0.271458'] 640.071\n",
      "[560, '0.074554', '45.18', '9.59', '0.421376'] 642.513\n",
      "[562, '0.046851', '46.85', '9.26', '0.273317'] 644.744\n",
      "[564, '0.046619', '46.69', '8.87', '0.270752'] 646.978\n",
      "[566, '0.046551', '46.72', '8.88', '0.271005'] 649.285\n",
      "[568, '0.046564', '46.68', '8.87', '0.270585'] 651.570\n",
      "[570, '0.074394', '45.16', '9.62', '0.422195'] 654.007\n",
      "[572, '0.046709', '46.84', '9.74', '0.273296'] 656.251\n",
      "[574, '0.046342', '46.71', '8.82', '0.271318'] 658.522\n",
      "[576, '0.046479', '46.80', '9.00', '0.272218'] 660.777\n",
      "[578, '0.046244', '46.80', '8.97', '0.273038'] 663.060\n",
      "[580, '0.074005', '45.08', '9.52', '0.418567'] 665.510\n",
      "[582, '0.046126', '46.73', '9.04', '0.270945'] 667.744\n",
      "[584, '0.046035', '46.76', '8.99', '0.271752'] 670.004\n",
      "[586, '0.046345', '47.17', '9.21', '0.278669'] 672.276\n",
      "[588, '0.045938', '46.71', '8.90', '0.269739'] 674.487\n",
      "[590, '0.073677', '45.12', '9.68', '0.415955'] 676.963\n",
      "[592, '0.045805', '46.78', '8.84', '0.272495'] 679.223\n",
      "[594, '0.045639', '46.62', '8.74', '0.269703'] 681.539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[596, '0.045596', '46.64', '8.76', '0.269874'] 683.767\n",
      "[598, '0.045465', '46.63', '8.84', '0.269468'] 686.056\n",
      "[600, '0.073405', '45.06', '9.45', '0.417618'] 688.548\n",
      "[602, '0.045423', '46.67', '8.72', '0.270780'] 690.854\n",
      "[604, '0.045319', '46.67', '8.72', '0.270420'] 693.118\n",
      "[606, '0.045185', '46.59', '8.76', '0.268919'] 695.369\n",
      "[608, '0.045131', '46.58', '8.70', '0.268916'] 697.640\n",
      "[610, '0.072979', '44.89', '9.37', '0.417470'] 700.111\n",
      "[612, '0.045039', '46.55', '8.92', '0.269467'] 702.368\n",
      "[614, '0.044835', '46.54', '8.67', '0.268580'] 704.629\n",
      "[616, '0.044800', '46.57', '8.85', '0.269226'] 706.922\n",
      "[618, '0.044836', '46.60', '8.71', '0.268786'] 709.149\n",
      "[620, '0.072637', '45.07', '9.66', '0.416797'] 711.592\n",
      "[622, '0.044623', '46.56', '8.79', '0.269148'] 713.872\n",
      "[624, '0.044627', '46.54', '8.75', '0.268919'] 716.137\n",
      "[626, '0.044411', '46.70', '8.74', '0.270391'] 718.336\n",
      "[628, '0.044334', '46.41', '8.69', '0.267264'] 720.569\n",
      "[630, '0.072104', '44.83', '9.17', '0.412892'] 723.039\n",
      "[632, '0.044107', '46.58', '8.80', '0.268956'] 725.226\n",
      "[634, '0.043941', '46.46', '8.56', '0.267470'] 727.542\n",
      "[636, '0.043860', '46.48', '8.62', '0.267779'] 729.780\n",
      "[638, '0.043768', '46.45', '8.58', '0.267170'] 731.984\n",
      "[640, '0.071906', '44.80', '9.46', '0.413330'] 734.429\n",
      "[642, '0.043657', '46.42', '8.70', '0.267464'] 736.689\n",
      "[644, '0.043544', '46.70', '8.62', '0.269512'] 738.938\n",
      "[646, '0.043350', '46.47', '8.71', '0.267077'] 741.252\n",
      "[648, '0.043318', '46.40', '8.63', '0.266696'] 743.525\n",
      "[650, '0.071266', '44.69', '9.01', '0.409833'] 745.939\n",
      "[652, '0.043055', '46.51', '8.72', '0.267907'] 748.300\n",
      "[654, '0.042991', '46.49', '8.71', '0.267384'] 750.622\n",
      "[656, '0.043062', '46.74', '8.59', '0.271506'] 752.977\n",
      "[658, '0.042865', '46.36', '8.66', '0.265964'] 755.270\n",
      "[660, '0.071461', '44.84', '9.29', '0.413780'] 757.739\n",
      "[662, '0.042696', '46.43', '8.72', '0.267030'] 759.951\n",
      "[664, '0.042465', '46.33', '8.56', '0.265423'] 762.219\n",
      "[666, '0.042384', '46.36', '8.52', '0.266029'] 764.518\n",
      "[668, '0.042316', '46.55', '8.39', '0.267776'] 766.768\n",
      "[670, '0.070583', '44.69', '8.96', '0.407959'] 769.243\n",
      "[672, '0.042156', '46.63', '8.57', '0.268715'] 771.473\n",
      "[674, '0.042010', '46.31', '8.56', '0.265327'] 773.740\n",
      "[676, '0.042071', '46.25', '8.83', '0.265501'] 775.979\n",
      "[678, '0.041923', '46.37', '8.53', '0.266315'] 778.232\n",
      "[680, '0.070489', '44.79', '8.97', '0.415570'] 780.754\n",
      "[682, '0.041790', '46.27', '8.88', '0.266084'] 783.018\n",
      "[684, '0.041434', '46.35', '8.55', '0.265520'] 785.278\n",
      "[686, '0.041394', '46.33', '8.48', '0.265154'] 787.541\n",
      "[688, '0.041336', '46.54', '8.62', '0.267422'] 789.740\n",
      "[690, '0.069899', '44.63', '8.98', '0.408074'] 792.215\n",
      "[692, '0.041221', '46.37', '8.18', '0.266729'] 794.485\n",
      "[694, '0.041208', '46.22', '8.58', '0.265134'] 796.736\n",
      "[696, '0.041023', '46.23', '8.20', '0.264936'] 798.944\n",
      "[698, '0.040932', '46.28', '8.50', '0.265104'] 801.225\n",
      "[700, '0.069578', '44.63', '8.98', '0.407118'] 803.673\n",
      "[702, '0.040867', '46.26', '8.53', '0.263968'] 805.884\n",
      "[704, '0.040785', '46.34', '8.49', '0.266694'] 808.132\n",
      "[706, '0.040643', '46.20', '8.17', '0.263154'] 810.360\n",
      "[708, '0.040578', '46.33', '8.41', '0.265973'] 812.612\n",
      "[710, '0.069517', '44.64', '9.13', '0.412571'] 815.061\n",
      "[712, '0.040461', '46.19', '8.51', '0.263918'] 817.278\n",
      "[714, '0.040313', '46.30', '8.47', '0.264992'] 819.663\n",
      "[716, '0.040164', '46.23', '8.25', '0.264152'] 821.939\n",
      "[718, '0.040258', '46.25', '8.45', '0.264912'] 824.212\n",
      "[720, '0.068853', '44.44', '8.83', '0.406101'] 826.674\n",
      "[722, '0.040167', '46.07', '8.21', '0.262618'] 828.923\n",
      "[724, '0.040069', '46.17', '8.21', '0.263614'] 831.195\n",
      "[726, '0.040043', '46.24', '8.59', '0.264028'] 833.435\n",
      "[728, '0.039969', '46.11', '8.45', '0.263591'] 835.636\n",
      "[730, '0.068657', '44.38', '9.00', '0.401573'] 838.111\n",
      "[732, '0.039903', '46.15', '8.30', '0.262711'] 840.352\n",
      "[734, '0.039893', '46.12', '8.29', '0.262714'] 842.566\n",
      "[736, '0.039784', '46.26', '8.75', '0.265504'] 844.857\n",
      "[738, '0.039915', '46.17', '8.23', '0.264019'] 847.153\n",
      "[740, '0.068561', '44.54', '9.48', '0.402058'] 849.644\n",
      "[742, '0.039738', '46.27', '8.16', '0.264698'] 851.905\n",
      "[744, '0.039738', '46.08', '8.50', '0.262384'] 854.212\n",
      "[746, '0.039633', '46.06', '8.05', '0.261693'] 856.328\n",
      "[748, '0.039642', '46.21', '8.04', '0.263940'] 858.582\n",
      "[750, '0.068515', '44.54', '9.03', '0.405844'] 861.068\n",
      "[752, '0.039596', '46.23', '8.53', '0.263762'] 863.279\n",
      "[754, '0.039549', '46.02', '8.12', '0.262021'] 865.567\n",
      "[756, '0.039549', '46.04', '8.27', '0.261961'] 867.832\n",
      "[758, '0.039498', '46.06', '8.24', '0.262188'] 870.100\n",
      "[760, '0.068406', '44.57', '9.05', '0.411914'] 872.577\n",
      "[762, '0.039569', '46.22', '8.05', '0.262050'] 874.733\n",
      "[764, '0.039652', '46.07', '8.79', '0.262889'] 877.027\n",
      "[766, '0.039349', '46.10', '8.25', '0.261931'] 879.238\n",
      "[768, '0.039478', '46.05', '7.96', '0.262080'] 881.494\n",
      "[770, '0.068148', '44.44', '8.68', '0.402349'] 884.001\n",
      "[772, '0.039394', '46.08', '8.31', '0.262672'] 886.233\n",
      "[774, '0.039345', '45.95', '8.18', '0.261348'] 888.479\n",
      "[776, '0.039361', '46.08', '8.20', '0.262508'] 890.733\n",
      "[778, '0.039293', '46.11', '8.27', '0.263381'] 893.073\n",
      "[780, '0.068213', '44.46', '8.78', '0.412574'] 895.523\n",
      "[782, '0.039598', '45.88', '8.91', '0.261447'] 897.743\n",
      "[784, '0.039290', '46.04', '8.12', '0.261871'] 899.991\n",
      "[786, '0.039288', '46.03', '8.37', '0.261184'] 902.227\n",
      "[788, '0.039299', '46.26', '8.33', '0.264285'] 904.457\n",
      "[790, '0.068081', '44.52', '8.89', '0.407248'] 906.901\n",
      "[792, '0.039262', '46.05', '8.20', '0.261926'] 909.111\n",
      "[794, '0.039402', '45.89', '8.27', '0.260514'] 911.454\n",
      "[796, '0.039137', '45.92', '8.35', '0.260383'] 913.722\n",
      "[798, '0.039219', '46.03', '8.07', '0.262815'] 915.957\n",
      "[800, '0.067821', '44.22', '8.58', '0.398724'] 918.401\n",
      "[802, '0.039398', '46.11', '8.23', '0.262382'] 920.637\n",
      "[804, '0.039181', '46.09', '8.21', '0.262307'] 922.927\n",
      "[806, '0.039398', '46.14', '8.20', '0.263334'] 925.243\n",
      "[808, '0.039173', '46.04', '8.43', '0.261385'] 927.491\n",
      "[810, '0.067758', '44.27', '8.73', '0.401949'] 929.962\n",
      "[812, '0.039086', '45.90', '8.29', '0.260232'] 932.203\n",
      "[814, '0.039169', '45.93', '8.30', '0.261085'] 934.469\n",
      "[816, '0.039155', '46.01', '8.04', '0.260495'] 936.757\n",
      "[818, '0.039061', '46.09', '8.21', '0.261962'] 938.923\n",
      "[820, '0.067798', '44.37', '8.95', '0.404241'] 941.400\n",
      "[822, '0.039030', '45.97', '8.28', '0.261132'] 943.675\n",
      "[824, '0.039085', '45.92', '8.05', '0.260231'] 945.929\n",
      "[826, '0.039051', '45.92', '8.36', '0.260674'] 948.147\n",
      "[828, '0.038961', '45.80', '8.11', '0.259307'] 950.420\n",
      "[830, '0.067779', '44.31', '8.64', '0.401880'] 952.920\n",
      "[832, '0.038950', '46.01', '8.16', '0.261156'] 955.176\n",
      "[834, '0.039008', '46.06', '8.40', '0.261706'] 957.442\n",
      "[836, '0.038980', '46.03', '7.97', '0.260600'] 959.709\n",
      "[838, '0.038964', '45.89', '7.95', '0.260434'] 962.006\n",
      "[840, '0.067842', '44.37', '8.57', '0.405440'] 964.379\n",
      "[842, '0.038893', '45.82', '8.03', '0.259365'] 966.573\n",
      "[844, '0.038933', '45.97', '7.97', '0.261111'] 968.832\n",
      "[846, '0.038946', '45.89', '8.11', '0.260391'] 971.074\n",
      "[848, '0.038939', '45.84', '7.84', '0.260184'] 973.375\n",
      "[850, '0.067493', '44.14', '8.71', '0.402170'] 975.806\n",
      "[852, '0.038965', '45.85', '7.98', '0.259976'] 978.046\n",
      "[854, '0.038913', '45.89', '8.06', '0.260818'] 980.321\n",
      "[856, '0.038946', '45.81', '8.34', '0.259535'] 982.580\n",
      "[858, '0.038845', '45.77', '8.05', '0.258675'] 984.827\n",
      "[860, '0.067859', '44.29', '8.71', '0.408950'] 987.304\n",
      "[862, '0.038964', '46.31', '8.68', '0.264587'] 989.518\n",
      "[864, '0.038799', '45.91', '8.35', '0.260362'] 991.766\n",
      "[866, '0.038846', '45.80', '7.96', '0.259698'] 994.031\n",
      "[868, '0.038864', '46.07', '8.08', '0.261288'] 996.320\n",
      "[870, '0.067304', '44.20', '9.13', '0.396965'] 998.801\n",
      "[872, '0.038895', '46.26', '8.36', '0.264489'] 1001.044\n",
      "[874, '0.038929', '46.06', '7.95', '0.262722'] 1003.415\n",
      "[876, '0.039024', '46.07', '8.86', '0.263269'] 1005.730\n",
      "[878, '0.038937', '45.97', '8.85', '0.260816'] 1007.965\n",
      "[880, '0.067328', '44.08', '8.61', '0.397363'] 1010.438\n",
      "[882, '0.038782', '45.89', '7.95', '0.259842'] 1012.680\n",
      "[884, '0.038930', '45.80', '8.01', '0.260549'] 1014.973\n",
      "[886, '0.038830', '46.05', '8.08', '0.263111'] 1017.270\n",
      "[888, '0.038673', '45.78', '8.55', '0.259721'] 1019.537\n",
      "[890, '0.067432', '44.20', '8.68', '0.405088'] 1021.985\n",
      "[892, '0.038729', '45.74', '8.04', '0.258226'] 1024.265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[894, '0.038799', '45.76', '8.27', '0.259024'] 1026.404\n",
      "[896, '0.038952', '45.78', '8.24', '0.260501'] 1028.628\n",
      "[898, '0.038755', '45.67', '7.90', '0.258454'] 1030.859\n",
      "[900, '0.067314', '44.00', '9.31', '0.397339'] 1033.300\n",
      "[902, '0.038752', '45.67', '8.11', '0.258297'] 1035.529\n",
      "[904, '0.038780', '45.91', '8.79', '0.261747'] 1037.804\n",
      "[906, '0.038832', '45.78', '7.95', '0.260045'] 1040.135\n",
      "[908, '0.038692', '45.64', '7.67', '0.257060'] 1042.433\n",
      "[910, '0.067213', '44.05', '8.58', '0.397827'] 1044.910\n",
      "[912, '0.038678', '45.67', '8.52', '0.258486'] 1047.153\n",
      "[914, '0.038853', '45.76', '8.11', '0.259384'] 1049.433\n",
      "[916, '0.038557', '45.91', '7.90', '0.259654'] 1051.668\n",
      "[918, '0.038688', '45.82', '8.50', '0.260813'] 1053.955\n",
      "[920, '0.067174', '44.06', '8.57', '0.400507'] 1056.407\n",
      "[922, '0.038755', '45.78', '8.31', '0.259571'] 1058.632\n",
      "[924, '0.038772', '45.83', '8.00', '0.260435'] 1060.897\n",
      "[926, '0.038560', '45.52', '7.62', '0.255275'] 1063.178\n",
      "[928, '0.038613', '45.78', '8.04', '0.259075'] 1065.453\n",
      "[930, '0.067113', '43.95', '8.70', '0.398161'] 1067.908\n",
      "[932, '0.038620', '45.74', '8.47', '0.258419'] 1070.195\n",
      "[934, '0.038585', '45.69', '8.06', '0.257880'] 1072.435\n",
      "[936, '0.038556', '45.67', '7.73', '0.257852'] 1074.718\n",
      "[938, '0.038696', '45.67', '8.25', '0.258027'] 1076.944\n",
      "[940, '0.067045', '43.97', '8.54', '0.399890'] 1079.408\n",
      "[942, '0.038667', '45.64', '7.93', '0.258353'] 1081.664\n",
      "[944, '0.038587', '45.73', '8.31', '0.259662'] 1083.910\n",
      "[946, '0.038603', '45.67', '7.90', '0.258248'] 1086.185\n",
      "[948, '0.038688', '45.68', '7.89', '0.257321'] 1088.400\n",
      "[950, '0.066982', '43.90', '8.54', '0.396453'] 1090.858\n",
      "[952, '0.038461', '45.71', '8.00', '0.258011'] 1093.136\n",
      "[954, '0.038665', '45.70', '8.14', '0.258110'] 1095.411\n",
      "[956, '0.038549', '45.53', '7.85', '0.256423'] 1097.657\n",
      "[958, '0.038481', '45.61', '7.94', '0.256986'] 1099.913\n",
      "[960, '0.067105', '43.87', '8.50', '0.398246'] 1102.434\n",
      "[962, '0.038588', '45.50', '8.16', '0.256235'] 1104.660\n",
      "[964, '0.038612', '45.54', '7.96', '0.256610'] 1106.875\n",
      "[966, '0.038717', '45.65', '8.36', '0.258688'] 1109.062\n",
      "[968, '0.038596', '45.75', '8.23', '0.259731'] 1111.317\n",
      "[970, '0.067400', '44.12', '8.66', '0.412265'] 1113.769\n",
      "[972, '0.038553', '45.49', '7.88', '0.255722'] 1115.976\n",
      "[974, '0.038477', '45.62', '7.73', '0.256567'] 1118.113\n",
      "[976, '0.038662', '45.48', '8.05', '0.255814'] 1120.407\n",
      "[978, '0.038524', '45.63', '8.18', '0.257017'] 1122.559\n",
      "[980, '0.067559', '44.35', '9.04', '0.421995'] 1125.036\n",
      "[982, '0.038539', '45.63', '9.44', '0.259682'] 1127.279\n",
      "[984, '0.038403', '45.57', '8.11', '0.256864'] 1129.519\n",
      "[986, '0.038407', '45.62', '7.97', '0.258129'] 1131.837\n",
      "[988, '0.038271', '45.72', '7.81', '0.258304'] 1134.022\n",
      "[990, '0.066764', '43.93', '9.36', '0.391648'] 1136.397\n",
      "[992, '0.038472', '45.52', '8.90', '0.256370'] 1138.685\n",
      "[994, '0.038448', '45.54', '8.13', '0.256601'] 1140.877\n",
      "[996, '0.038606', '45.56', '8.15', '0.256367'] 1143.075\n",
      "[998, '0.038320', '45.49', '7.92', '0.256054'] 1145.286\n",
      "[1000, '0.067012', '43.96', '8.90', '0.404067'] 1147.753\n",
      "[1002, '0.038304', '45.48', '8.39', '0.256122'] 1150.053\n",
      "[1004, '0.038488', '45.63', '7.73', '0.258651'] 1152.282\n",
      "[1006, '0.038354', '45.51', '8.48', '0.256217'] 1154.494\n",
      "[1008, '0.038427', '45.69', '7.67', '0.257229'] 1156.728\n",
      "[1010, '0.066735', '43.87', '8.75', '0.400156'] 1159.114\n",
      "[1012, '0.038670', '45.51', '7.73', '0.255116'] 1161.362\n",
      "[1014, '0.038304', '45.55', '8.10', '0.256230'] 1163.605\n",
      "[1016, '0.038292', '45.44', '7.86', '0.254819'] 1165.866\n",
      "[1018, '0.038349', '45.88', '7.92', '0.260625'] 1168.113\n",
      "[1020, '0.066796', '43.79', '8.63', '0.399667'] 1170.563\n",
      "[1022, '0.038392', '45.55', '8.06', '0.256649'] 1172.897\n",
      "[1024, '0.038236', '45.49', '7.59', '0.255620'] 1175.164\n",
      "[1026, '0.038390', '45.43', '7.76', '0.255152'] 1177.442\n",
      "[1028, '0.038331', '45.50', '8.22', '0.257423'] 1179.697\n",
      "[1030, '0.066993', '44.19', '8.81', '0.403886'] 1182.164\n",
      "[1032, '0.038248', '45.55', '8.01', '0.256347'] 1184.368\n",
      "[1034, '0.038353', '45.44', '7.67', '0.255367'] 1186.549\n",
      "[1036, '0.038319', '45.39', '7.95', '0.254789'] 1188.773\n",
      "[1038, '0.038362', '45.60', '7.87', '0.256966'] 1191.064\n",
      "[1040, '0.066537', '43.69', '8.25', '0.391952'] 1193.564\n",
      "[1042, '0.038180', '45.50', '7.74', '0.255235'] 1195.857\n",
      "[1044, '0.038364', '45.45', '7.97', '0.255142'] 1198.115\n",
      "[1046, '0.038292', '45.45', '8.01', '0.255519'] 1200.330\n",
      "[1048, '0.038434', '45.80', '7.84', '0.259286'] 1202.579\n",
      "[1050, '0.066741', '43.79', '8.41', '0.395768'] 1205.036\n",
      "[1052, '0.038232', '45.46', '7.89', '0.255889'] 1207.257\n",
      "[1054, '0.038438', '45.40', '8.36', '0.254961'] 1209.524\n",
      "[1056, '0.038267', '45.42', '7.95', '0.255045'] 1211.820\n",
      "[1058, '0.038335', '45.31', '7.67', '0.252784'] 1214.115\n",
      "[1060, '0.066963', '44.07', '8.31', '0.404850'] 1216.546\n",
      "[1062, '0.038357', '45.40', '7.77', '0.254567'] 1218.808\n",
      "[1064, '0.038237', '45.46', '8.02', '0.254805'] 1221.060\n",
      "[1066, '0.038434', '45.42', '8.05', '0.254712'] 1223.304\n",
      "[1068, '0.038290', '45.86', '8.28', '0.262868'] 1225.556\n",
      "[1070, '0.066504', '43.63', '8.37', '0.390703'] 1227.963\n",
      "[1072, '0.038336', '45.40', '8.07', '0.255130'] 1230.191\n",
      "[1074, '0.038247', '45.34', '8.12', '0.254831'] 1232.532\n",
      "[1076, '0.038189', '45.54', '8.01', '0.256421'] 1234.892\n",
      "[1078, '0.038324', '45.32', '8.03', '0.254092'] 1237.086\n",
      "[1080, '0.066356', '43.60', '8.30', '0.388684'] 1239.502\n",
      "[1082, '0.038266', '45.47', '7.73', '0.254718'] 1241.689\n",
      "[1084, '0.038239', '45.46', '8.22', '0.256197'] 1243.923\n",
      "[1086, '0.038128', '45.35', '7.92', '0.254235'] 1246.184\n",
      "[1088, '0.038059', '45.47', '7.83', '0.254877'] 1248.412\n",
      "[1090, '0.066882', '43.91', '9.07', '0.405185'] 1250.861\n",
      "[1092, '0.038295', '45.30', '8.53', '0.254336'] 1253.202\n",
      "[1094, '0.038345', '45.59', '7.88', '0.257921'] 1255.430\n",
      "[1096, '0.038209', '45.35', '7.93', '0.255131'] 1257.694\n",
      "[1098, '0.038138', '45.34', '8.04', '0.253921'] 1259.958\n",
      "[1100, '0.066314', '43.64', '8.73', '0.392986'] 1262.412\n",
      "[1102, '0.038226', '45.37', '7.39', '0.253741'] 1264.680\n",
      "[1104, '0.038066', '45.24', '8.21', '0.253544'] 1266.891\n",
      "[1106, '0.038024', '45.55', '7.55', '0.256392'] 1269.098\n",
      "[1108, '0.037949', '45.48', '7.59', '0.255703'] 1271.363\n",
      "[1110, '0.066630', '43.70', '8.48', '0.396533'] 1273.800\n",
      "[1112, '0.038053', '45.31', '7.75', '0.253594'] 1276.050\n",
      "[1114, '0.038182', '45.62', '7.96', '0.257886'] 1278.364\n",
      "[1116, '0.038434', '45.82', '8.05', '0.261354'] 1280.663\n",
      "[1118, '0.038301', '45.42', '8.37', '0.255687'] 1282.898\n",
      "[1120, '0.066488', '43.68', '8.19', '0.394269'] 1285.341\n",
      "[1122, '0.038156', '45.11', '8.46', '0.251850'] 1287.671\n",
      "[1124, '0.038107', '45.29', '7.79', '0.253510'] 1289.903\n",
      "[1126, '0.038090', '45.22', '7.95', '0.252772'] 1292.151\n",
      "[1128, '0.038080', '45.36', '7.88', '0.252610'] 1294.448\n",
      "[1130, '0.066330', '43.66', '8.55', '0.396452'] 1296.873\n",
      "[1132, '0.038012', '45.30', '7.77', '0.253422'] 1299.070\n",
      "[1134, '0.038158', '45.32', '8.35', '0.255131'] 1301.317\n",
      "[1136, '0.038098', '45.33', '7.62', '0.253661'] 1303.587\n",
      "[1138, '0.038003', '45.35', '7.46', '0.253155'] 1305.841\n",
      "[1140, '0.066345', '43.66', '8.32', '0.390779'] 1308.339\n",
      "[1142, '0.038042', '45.42', '7.54', '0.255529'] 1310.617\n",
      "[1144, '0.037988', '45.18', '7.59', '0.251713'] 1312.847\n",
      "[1146, '0.038393', '45.33', '7.47', '0.254180'] 1315.145\n",
      "[1148, '0.038243', '45.28', '7.87', '0.254557'] 1317.414\n",
      "[1150, '0.066333', '43.61', '8.25', '0.393705'] 1319.897\n",
      "[1152, '0.038038', '45.23', '7.95', '0.253040'] 1322.235\n",
      "[1154, '0.037890', '45.30', '7.53', '0.252653'] 1324.537\n",
      "[1156, '0.038068', '45.15', '7.66', '0.251973'] 1326.803\n",
      "[1158, '0.037873', '45.24', '7.63', '0.251916'] 1329.064\n",
      "[1160, '0.066660', '43.70', '8.75', '0.405247'] 1331.539\n",
      "[1162, '0.037983', '45.35', '7.69', '0.253415'] 1333.803\n",
      "[1164, '0.038021', '45.23', '7.54', '0.252112'] 1336.101\n",
      "[1166, '0.037994', '45.56', '7.84', '0.255430'] 1338.366\n",
      "[1168, '0.037933', '45.19', '7.78', '0.252087'] 1340.652\n",
      "[1170, '0.066439', '43.54', '8.66', '0.399985'] 1343.136\n",
      "[1172, '0.037989', '45.26', '7.70', '0.252875'] 1345.343\n",
      "[1174, '0.037908', '45.48', '8.26', '0.255759'] 1347.590\n",
      "[1176, '0.037915', '45.29', '7.68', '0.253561'] 1349.803\n",
      "[1178, '0.038085', '45.32', '7.90', '0.253972'] 1352.051\n",
      "[1180, '0.066804', '43.96', '8.68', '0.409047'] 1354.481\n",
      "[1182, '0.037778', '45.21', '7.65', '0.252483'] 1356.698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1184, '0.037943', '45.17', '7.86', '0.251674'] 1359.025\n",
      "[1186, '0.037906', '45.18', '7.26', '0.251855'] 1361.236\n",
      "[1188, '0.037864', '45.16', '7.55', '0.252206'] 1363.541\n",
      "[1190, '0.066569', '43.71', '8.38', '0.400529'] 1366.001\n",
      "[1192, '0.037912', '45.10', '7.81', '0.251458'] 1368.262\n",
      "[1194, '0.037922', '45.13', '7.67', '0.252035'] 1370.507\n",
      "[1196, '0.038055', '45.15', '7.86', '0.252166'] 1372.812\n",
      "[1198, '0.037833', '45.12', '7.63', '0.252156'] 1375.072\n",
      "[1200, '0.066319', '43.67', '8.30', '0.401451'] 1377.496\n",
      "[1202, '0.037801', '45.18', '7.30', '0.252394'] 1379.811\n",
      "[1204, '0.038015', '45.08', '8.33', '0.252485'] 1382.090\n",
      "[1206, '0.037792', '45.21', '8.05', '0.252626'] 1384.278\n",
      "[1208, '0.037880', '45.08', '7.57', '0.252109'] 1386.450\n",
      "[1210, '0.066024', '43.47', '8.12', '0.393296'] 1388.943\n",
      "[1212, '0.038039', '45.10', '7.59', '0.250558'] 1391.123\n",
      "[1214, '0.037896', '45.15', '7.71', '0.252565'] 1393.363\n",
      "[1216, '0.037779', '45.18', '7.66', '0.251724'] 1395.613\n",
      "[1218, '0.038068', '45.33', '7.48', '0.253278'] 1397.852\n",
      "[1220, '0.066185', '43.45', '8.02', '0.388836'] 1400.295\n",
      "[1222, '0.037776', '45.11', '7.32', '0.250849'] 1402.565\n",
      "[1224, '0.037770', '45.24', '7.78', '0.253261'] 1404.832\n",
      "[1226, '0.037764', '45.11', '7.50', '0.251586'] 1407.069\n",
      "[1228, '0.037898', '45.02', '8.17', '0.251092'] 1409.328\n",
      "[1230, '0.066211', '43.56', '8.30', '0.394303'] 1411.790\n",
      "[1232, '0.037802', '45.16', '7.22', '0.252452'] 1414.019\n",
      "[1234, '0.037907', '45.23', '7.38', '0.251980'] 1416.329\n",
      "[1236, '0.037741', '45.18', '7.49', '0.252206'] 1418.596\n",
      "[1238, '0.037965', '45.42', '7.49', '0.254187'] 1420.880\n",
      "[1240, '0.066213', '43.78', '8.36', '0.394991'] 1423.292\n",
      "[1242, '0.038209', '45.21', '8.14', '0.254310'] 1425.563\n",
      "[1244, '0.037783', '45.02', '7.65', '0.251193'] 1427.837\n",
      "[1246, '0.037898', '45.10', '7.91', '0.252926'] 1430.067\n",
      "[1248, '0.037904', '45.11', '8.00', '0.252908'] 1432.259\n",
      "[1250, '0.065971', '43.37', '8.39', '0.387806'] 1434.710\n",
      "[1252, '0.037804', '45.04', '7.67', '0.250904'] 1437.043\n",
      "[1254, '0.037827', '45.24', '7.33', '0.252234'] 1439.364\n",
      "[1256, '0.037725', '45.12', '7.24', '0.251172'] 1441.619\n",
      "[1258, '0.037897', '45.01', '7.38', '0.250017'] 1443.868\n",
      "[1260, '0.066390', '43.63', '8.37', '0.404021'] 1446.356\n",
      "[1262, '0.037556', '45.17', '7.38', '0.252411'] 1448.607\n",
      "[1264, '0.038103', '45.39', '8.07', '0.255215'] 1450.848\n",
      "[1266, '0.037654', '45.05', '7.39', '0.250831'] 1453.073\n",
      "[1268, '0.037783', '44.98', '8.10', '0.251334'] 1455.327\n",
      "[1270, '0.065947', '43.34', '8.60', '0.389225'] 1457.766\n",
      "[1272, '0.037991', '45.13', '7.89', '0.253246'] 1460.029\n",
      "[1274, '0.037731', '45.16', '8.37', '0.252856'] 1462.284\n",
      "[1276, '0.037700', '45.03', '7.50', '0.250300'] 1464.542\n",
      "[1278, '0.037856', '44.97', '7.77', '0.250596'] 1466.811\n",
      "[1280, '0.066129', '43.51', '8.36', '0.391652'] 1469.277\n",
      "[1282, '0.037742', '45.15', '7.99', '0.253846'] 1471.587\n",
      "[1284, '0.037661', '45.20', '7.34', '0.251776'] 1473.825\n",
      "[1286, '0.037663', '45.07', '7.52', '0.250862'] 1476.087\n",
      "[1288, '0.037644', '44.94', '7.19', '0.248070'] 1478.341\n",
      "[1290, '0.065723', '43.26', '8.42', '0.389112'] 1480.791\n",
      "[1292, '0.037647', '44.96', '8.20', '0.250846'] 1482.955\n",
      "[1294, '0.037559', '44.97', '7.58', '0.249712'] 1485.182\n",
      "[1296, '0.037453', '45.44', '7.57', '0.254821'] 1487.432\n",
      "[1298, '0.037528', '45.25', '7.52', '0.252332'] 1489.632\n",
      "[1300, '0.065884', '43.29', '8.16', '0.389954'] 1492.109\n",
      "[1302, '0.037626', '44.92', '8.00', '0.249616'] 1494.312\n",
      "[1304, '0.037647', '45.05', '7.64', '0.250912'] 1496.589\n",
      "[1306, '0.037758', '44.90', '7.79', '0.249357'] 1498.870\n",
      "[1308, '0.037554', '44.90', '7.40', '0.249028'] 1501.117\n",
      "[1310, '0.066404', '43.84', '8.71', '0.409841'] 1503.566\n",
      "[1312, '0.037565', '44.89', '7.69', '0.249134'] 1505.796\n",
      "[1314, '0.037551', '44.95', '7.58', '0.249487'] 1508.033\n",
      "[1316, '0.037467', '44.96', '7.24', '0.249365'] 1510.290\n",
      "[1318, '0.037996', '45.35', '7.75', '0.251614'] 1512.554\n",
      "[1320, '0.066102', '43.36', '8.36', '0.392632'] 1515.032\n",
      "[1322, '0.037663', '45.01', '7.21', '0.250965'] 1517.290\n",
      "[1324, '0.037501', '45.23', '7.49', '0.251816'] 1519.508\n",
      "[1326, '0.037687', '44.92', '8.25', '0.250518'] 1521.783\n",
      "[1328, '0.037487', '44.94', '7.37', '0.249383'] 1524.105\n",
      "[1330, '0.065761', '43.18', '8.33', '0.389001'] 1526.486\n",
      "[1332, '0.037517', '44.86', '7.67', '0.248717'] 1528.740\n",
      "[1334, '0.037453', '45.13', '7.44', '0.251177'] 1530.959\n",
      "[1336, '0.037628', '44.94', '7.46', '0.248711'] 1533.208\n",
      "[1338, '0.037622', '45.29', '7.42', '0.252480'] 1535.413\n",
      "[1340, '0.065910', '43.39', '8.87', '0.387839'] 1537.925\n",
      "[1342, '0.037426', '44.97', '7.58', '0.249665'] 1540.179\n",
      "[1344, '0.037653', '45.00', '8.16', '0.251780'] 1542.430\n",
      "[1346, '0.037703', '44.98', '8.08', '0.250513'] 1544.615\n",
      "[1348, '0.037363', '45.11', '7.13', '0.251042'] 1546.846\n",
      "[1350, '0.065877', '43.35', '8.36', '0.392197'] 1549.289\n",
      "[1352, '0.037540', '44.96', '7.68', '0.249471'] 1551.595\n",
      "[1354, '0.037689', '45.12', '7.92', '0.251749'] 1553.850\n",
      "[1356, '0.037461', '44.85', '7.42', '0.248463'] 1556.144\n",
      "[1358, '0.037434', '44.85', '7.52', '0.249019'] 1558.381\n",
      "[1360, '0.066214', '43.37', '8.62', '0.400434'] 1560.812\n",
      "[1362, '0.037284', '44.91', '7.40', '0.248542'] 1563.086\n",
      "[1364, '0.037530', '44.98', '7.42', '0.249926'] 1565.313\n",
      "[1366, '0.037401', '45.14', '7.41', '0.251175'] 1567.461\n",
      "[1368, '0.037759', '45.45', '7.58', '0.253043'] 1569.751\n",
      "[1370, '0.065835', '43.27', '8.19', '0.389620'] 1572.172\n",
      "[1372, '0.037401', '44.86', '7.23', '0.248743'] 1574.419\n",
      "[1374, '0.037550', '45.03', '7.80', '0.251482'] 1576.742\n",
      "[1376, '0.037485', '44.73', '7.52', '0.246778'] 1578.999\n",
      "[1378, '0.037484', '44.83', '8.00', '0.249086'] 1581.306\n",
      "[1380, '0.065952', '43.31', '8.76', '0.397045'] 1583.719\n",
      "[1382, '0.037745', '44.98', '8.38', '0.252585'] 1586.073\n",
      "[1384, '0.037550', '45.29', '8.22', '0.254260'] 1588.300\n",
      "[1386, '0.037415', '45.12', '8.19', '0.253090'] 1590.549\n",
      "[1388, '0.037306', '45.11', '7.27', '0.250884'] 1592.774\n",
      "[1390, '0.065823', '43.23', '8.03', '0.390065'] 1595.197\n",
      "[1392, '0.037420', '44.92', '7.03', '0.248620'] 1597.419\n",
      "[1394, '0.037248', '44.90', '7.72', '0.249213'] 1599.706\n",
      "[1396, '0.037390', '44.88', '7.81', '0.249520'] 1601.939\n",
      "[1398, '0.037283', '44.91', '7.34', '0.249443'] 1604.216\n",
      "[1400, '0.065643', '43.20', '8.35', '0.387337'] 1606.815\n",
      "[1402, '0.037331', '44.85', '7.32', '0.248595'] 1608.985\n",
      "[1404, '0.037250', '45.10', '7.35', '0.250464'] 1611.222\n",
      "[1406, '0.037381', '44.97', '7.07', '0.249821'] 1613.455\n",
      "[1408, '0.037310', '44.81', '7.45', '0.248307'] 1615.650\n",
      "[1410, '0.065781', '43.32', '8.43', '0.392763'] 1618.086\n",
      "[1412, '0.037269', '44.72', '7.46', '0.246806'] 1620.285\n",
      "[1414, '0.037309', '44.78', '7.65', '0.247736'] 1622.536\n",
      "[1416, '0.037291', '44.84', '7.45', '0.248105'] 1624.783\n",
      "[1418, '0.037504', '44.89', '7.65', '0.250066'] 1627.045\n",
      "[1420, '0.066149', '43.44', '8.30', '0.400738'] 1629.472\n",
      "[1422, '0.037433', '44.91', '7.94', '0.250132'] 1631.694\n",
      "[1424, '0.037667', '44.67', '8.17', '0.247208'] 1633.945\n",
      "[1426, '0.037327', '44.91', '7.07', '0.249331'] 1636.198\n",
      "[1428, '0.037437', '44.80', '8.27', '0.250128'] 1638.454\n",
      "[1430, '0.065618', '43.35', '8.25', '0.388512'] 1640.916\n",
      "[1432, '0.037279', '44.95', '7.32', '0.249627'] 1643.170\n",
      "[1434, '0.037431', '44.87', '7.56', '0.249147'] 1645.508\n",
      "[1436, '0.037210', '44.68', '7.45', '0.246775'] 1647.758\n",
      "[1438, '0.037174', '44.95', '7.31', '0.248940'] 1650.024\n",
      "[1440, '0.065799', '43.33', '8.45', '0.398812'] 1652.462\n",
      "[1442, '0.037401', '44.85', '7.16', '0.248648'] 1654.682\n",
      "[1444, '0.037222', '44.82', '7.48', '0.248272'] 1656.901\n",
      "[1446, '0.037331', '44.86', '7.42', '0.248714'] 1659.152\n",
      "[1448, '0.037277', '44.74', '7.75', '0.247732'] 1661.360\n",
      "[1450, '0.066050', '43.34', '8.62', '0.405258'] 1663.789\n",
      "[1452, '0.037300', '44.92', '7.38', '0.249985'] 1666.054\n",
      "[1454, '0.037096', '44.89', '7.18', '0.249147'] 1668.292\n",
      "[1456, '0.037270', '44.77', '7.93', '0.248064'] 1670.561\n",
      "[1458, '0.037039', '45.13', '7.30', '0.250868'] 1672.764\n",
      "[1460, '0.065530', '43.12', '8.22', '0.386483'] 1675.188\n",
      "[1462, '0.037287', '44.89', '7.72', '0.249835'] 1677.494\n",
      "[1464, '0.037194', '44.95', '7.25', '0.248711'] 1679.708\n",
      "[1466, '0.037115', '44.78', '7.19', '0.247268'] 1681.973\n",
      "[1468, '0.037302', '44.90', '8.01', '0.249802'] 1684.224\n",
      "[1470, '0.065521', '43.09', '8.05', '0.387079'] 1686.696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1472, '0.037235', '44.68', '7.72', '0.246915'] 1688.909\n",
      "[1474, '0.037280', '44.81', '8.55', '0.250755'] 1691.147\n",
      "[1476, '0.037128', '44.76', '7.39', '0.247520'] 1693.446\n",
      "[1478, '0.037130', '44.75', '7.32', '0.247307'] 1695.719\n",
      "[1480, '0.065599', '43.14', '8.25', '0.391182'] 1698.145\n",
      "[1482, '0.037269', '45.06', '7.30', '0.251000'] 1700.383\n",
      "[1484, '0.037183', '44.75', '7.03', '0.246375'] 1702.551\n",
      "[1486, '0.037196', '44.70', '7.16', '0.247105'] 1704.766\n",
      "[1488, '0.037088', '44.84', '7.33', '0.247636'] 1707.049\n",
      "[1490, '0.065372', '43.06', '8.26', '0.384178'] 1709.505\n",
      "[1492, '0.037409', '44.94', '6.90', '0.249586'] 1711.769\n",
      "[1494, '0.037116', '44.83', '7.08', '0.248100'] 1714.019\n",
      "[1496, '0.037194', '44.75', '7.49', '0.246998'] 1716.263\n",
      "[1498, '0.037093', '44.78', '7.16', '0.246926'] 1718.464\n",
      "[1500, '0.065301', '42.89', '8.11', '0.382363'] 1720.943\n",
      "[1502, '0.037171', '44.81', '7.31', '0.247176'] 1723.195\n",
      "[1504, '0.037119', '44.76', '6.96', '0.246613'] 1725.443\n",
      "[1506, '0.037056', '44.72', '7.38', '0.246867'] 1727.733\n",
      "[1508, '0.037539', '44.55', '8.14', '0.247439'] 1729.979\n",
      "[1510, '0.065319', '42.97', '7.86', '0.383147'] 1732.460\n",
      "[1512, '0.037235', '44.97', '7.23', '0.248534'] 1734.716\n",
      "[1514, '0.036993', '44.78', '7.09', '0.247365'] 1736.932\n",
      "[1516, '0.037204', '44.88', '8.03', '0.250029'] 1739.178\n",
      "[1518, '0.037086', '44.68', '7.07', '0.244527'] 1741.488\n",
      "[1520, '0.065290', '43.26', '7.88', '0.387235'] 1743.908\n",
      "[1522, '0.037136', '44.80', '7.35', '0.248194'] 1746.072\n",
      "[1524, '0.037081', '44.75', '7.46', '0.248176'] 1748.310\n",
      "[1526, '0.037078', '44.84', '7.51', '0.247931'] 1750.537\n",
      "[1528, '0.037050', '44.94', '7.77', '0.250064'] 1752.797\n",
      "[1530, '0.065705', '43.28', '8.28', '0.396448'] 1755.320\n",
      "[1532, '0.037323', '44.59', '8.21', '0.247065'] 1757.600\n",
      "[1534, '0.037133', '44.96', '7.29', '0.248946'] 1759.852\n",
      "[1536, '0.036967', '44.78', '6.92', '0.247677'] 1762.152\n",
      "[1538, '0.037121', '44.90', '7.46', '0.248627'] 1764.390\n",
      "[1540, '0.065725', '43.29', '8.33', '0.398356'] 1766.795\n",
      "[1542, '0.037078', '44.69', '7.64', '0.247815'] 1769.069\n",
      "[1544, '0.037025', '44.78', '7.58', '0.247699'] 1771.339\n",
      "[1546, '0.036934', '44.61', '7.21', '0.246495'] 1773.590\n",
      "[1548, '0.037044', '44.51', '7.82', '0.245789'] 1775.813\n",
      "[1550, '0.065401', '43.15', '8.00', '0.388162'] 1778.243\n",
      "[1552, '0.037149', '44.56', '7.32', '0.246119'] 1780.442\n",
      "[1554, '0.037022', '44.77', '7.72', '0.248937'] 1782.732\n",
      "[1556, '0.036966', '44.60', '7.26', '0.245360'] 1784.931\n",
      "[1558, '0.036973', '44.57', '7.35', '0.245651'] 1787.183\n",
      "[1560, '0.065233', '42.91', '9.30', '0.379715'] 1789.614\n",
      "[1562, '0.036939', '44.89', '7.11', '0.248887'] 1791.795\n",
      "[1564, '0.036912', '44.74', '7.37', '0.247417'] 1794.088\n",
      "[1566, '0.036963', '44.90', '7.21', '0.249051'] 1796.361\n",
      "[1568, '0.037151', '44.59', '8.22', '0.248045'] 1798.614\n",
      "[1570, '0.065307', '43.16', '8.54', '0.394124'] 1801.067\n",
      "[1572, '0.037019', '44.88', '7.80', '0.249859'] 1803.282\n",
      "[1574, '0.036999', '44.82', '7.41', '0.248379'] 1805.451\n",
      "[1576, '0.036983', '44.69', '7.51', '0.246919'] 1807.709\n",
      "[1578, '0.037170', '44.94', '7.23', '0.248953'] 1810.046\n",
      "[1580, '0.065145', '42.95', '7.57', '0.381088'] 1812.522\n",
      "[1582, '0.037126', '44.94', '6.97', '0.250772'] 1814.746\n",
      "[1584, '0.036854', '44.81', '7.28', '0.247965'] 1817.024\n",
      "[1586, '0.036898', '44.48', '7.18', '0.243467'] 1819.297\n",
      "[1588, '0.036768', '44.71', '7.22', '0.247086'] 1821.528\n",
      "[1590, '0.066050', '43.23', '8.89', '0.407351'] 1823.991\n",
      "[1592, '0.036888', '45.03', '7.47', '0.250333'] 1826.223\n",
      "[1594, '0.036920', '44.57', '7.43', '0.245407'] 1828.452\n",
      "[1596, '0.036921', '44.61', '7.29', '0.246459'] 1830.654\n",
      "[1598, '0.036881', '44.67', '7.28', '0.246477'] 1832.911\n",
      "[1600, '0.065524', '43.04', '8.54', '0.397884'] 1835.376\n",
      "[1602, '0.036831', '44.50', '7.31', '0.245169'] 1837.571\n",
      "[1604, '0.036955', '44.58', '7.72', '0.246315'] 1839.869\n",
      "[1606, '0.036897', '44.68', '7.27', '0.246003'] 1842.224\n",
      "[1608, '0.036951', '44.76', '7.37', '0.247970'] 1844.421\n",
      "[1610, '0.065589', '43.11', '8.20', '0.392077'] 1846.888\n",
      "[1612, '0.037081', '44.75', '7.08', '0.247931'] 1849.146\n",
      "[1614, '0.036944', '44.91', '7.27', '0.248305'] 1851.370\n",
      "[1616, '0.036805', '44.56', '6.85', '0.245366'] 1853.628\n",
      "[1618, '0.036954', '44.56', '8.17', '0.245983'] 1855.876\n",
      "[1620, '0.065640', '43.10', '8.37', '0.393967'] 1858.313\n",
      "[1622, '0.036968', '44.67', '7.57', '0.247139'] 1860.537\n",
      "[1624, '0.037303', '44.46', '8.68', '0.246318'] 1862.770\n",
      "[1626, '0.036857', '44.79', '7.43', '0.249141'] 1865.047\n",
      "[1628, '0.036922', '44.95', '8.26', '0.252756'] 1867.327\n",
      "[1630, '0.065371', '43.10', '8.72', '0.391794'] 1869.657\n",
      "[1632, '0.037040', '44.48', '7.98', '0.245951'] 1871.891\n",
      "[1634, '0.036723', '44.62', '7.02', '0.245839'] 1874.157\n",
      "[1636, '0.037221', '44.59', '8.57', '0.247005'] 1876.421\n",
      "[1638, '0.036901', '44.60', '7.77', '0.246746'] 1878.664\n",
      "[1640, '0.065688', '43.08', '8.08', '0.392577'] 1881.132\n",
      "[1642, '0.036840', '44.42', '7.61', '0.245531'] 1883.367\n",
      "[1644, '0.036814', '44.44', '7.36', '0.244728'] 1885.556\n",
      "[1646, '0.036860', '44.56', '7.16', '0.246756'] 1887.841\n",
      "[1648, '0.036724', '44.65', '7.53', '0.246929'] 1890.096\n",
      "[1650, '0.065124', '42.82', '8.14', '0.382501'] 1892.512\n",
      "[1652, '0.036809', '44.46', '7.36', '0.244256'] 1894.762\n",
      "[1654, '0.036839', '44.73', '7.36', '0.248664'] 1896.999\n",
      "[1656, '0.036861', '44.66', '7.45', '0.246716'] 1899.250\n",
      "[1658, '0.036969', '44.70', '7.20', '0.248489'] 1901.504\n",
      "[1660, '0.065723', '43.14', '8.32', '0.394875'] 1903.935\n",
      "[1662, '0.036759', '44.51', '7.21', '0.243820'] 1906.172\n",
      "[1664, '0.036782', '44.47', '7.35', '0.244099'] 1908.416\n",
      "[1666, '0.036795', '44.51', '7.99', '0.245999'] 1910.662\n",
      "[1668, '0.036909', '44.46', '7.25', '0.244951'] 1912.889\n",
      "[1670, '0.065101', '43.09', '8.16', '0.379718'] 1915.338\n",
      "[1672, '0.036870', '44.71', '7.17', '0.248403'] 1917.621\n",
      "[1674, '0.036905', '44.90', '8.98', '0.254526'] 1919.890\n",
      "[1676, '0.036647', '44.63', '7.06', '0.245549'] 1922.144\n",
      "[1678, '0.036782', '44.55', '7.01', '0.245054'] 1924.482\n",
      "[1680, '0.065060', '42.84', '7.93', '0.383344'] 1926.930\n",
      "[1682, '0.037025', '44.60', '7.35', '0.247460'] 1929.230\n",
      "[1684, '0.036708', '44.55', '6.91', '0.244554'] 1931.472\n",
      "[1686, '0.036834', '44.39', '7.63', '0.244265'] 1933.712\n",
      "[1688, '0.036678', '44.40', '7.15', '0.243780'] 1935.926\n",
      "[1690, '0.065801', '43.27', '8.44', '0.401842'] 1938.264\n",
      "[1692, '0.036780', '44.48', '7.71', '0.245254'] 1940.463\n",
      "[1694, '0.036831', '44.51', '7.25', '0.245697'] 1942.710\n",
      "[1696, '0.036582', '44.46', '7.10', '0.243669'] 1944.954\n",
      "[1698, '0.036701', '44.37', '7.20', '0.243188'] 1947.189\n",
      "[1700, '0.065304', '43.08', '8.46', '0.391182'] 1949.647\n",
      "[1702, '0.036760', '44.63', '6.93', '0.245554'] 1951.751\n",
      "[1704, '0.036730', '44.50', '7.41', '0.244948'] 1954.033\n",
      "[1706, '0.036702', '44.42', '7.42', '0.244376'] 1956.304\n",
      "[1708, '0.036685', '44.43', '7.30', '0.244661'] 1958.616\n",
      "[1710, '0.064921', '42.77', '7.92', '0.382270'] 1961.077\n",
      "[1712, '0.036856', '44.52', '8.10', '0.245984'] 1963.339\n",
      "[1714, '0.036675', '44.65', '7.26', '0.245626'] 1965.574\n",
      "[1716, '0.036759', '44.61', '7.08', '0.245782'] 1967.769\n",
      "[1718, '0.036540', '44.64', '7.07', '0.245749'] 1969.955\n",
      "[1720, '0.065098', '42.74', '8.07', '0.380550'] 1972.440\n",
      "[1722, '0.036730', '44.50', '7.55', '0.244301'] 1974.710\n",
      "[1724, '0.036770', '44.41', '7.22', '0.244877'] 1976.952\n",
      "[1726, '0.036789', '44.36', '7.67', '0.244201'] 1979.229\n",
      "[1728, '0.036579', '44.63', '7.04', '0.247216'] 1981.491\n",
      "[1730, '0.065508', '43.01', '8.15', '0.393462'] 1983.942\n",
      "[1732, '0.036608', '44.41', '7.17', '0.242884'] 1986.170\n",
      "[1734, '0.036699', '44.50', '7.31', '0.245243'] 1988.373\n",
      "[1736, '0.036912', '44.18', '7.84', '0.242141'] 1990.547\n",
      "[1738, '0.036710', '44.58', '7.37', '0.245107'] 1992.803\n",
      "[1740, '0.065121', '42.78', '8.11', '0.385575'] 1995.283\n",
      "[1742, '0.036785', '44.91', '7.34', '0.248057'] 1997.535\n",
      "[1744, '0.036547', '44.36', '7.12', '0.242305'] 1999.807\n",
      "[1746, '0.036508', '44.68', '7.70', '0.247413'] 2002.090\n",
      "[1748, '0.036502', '44.67', '7.33', '0.246086'] 2004.341\n",
      "[1750, '0.065296', '42.82', '8.49', '0.386179'] 2006.783\n",
      "[1752, '0.036610', '44.40', '6.93', '0.243972'] 2009.035\n",
      "[1754, '0.036463', '44.36', '7.11', '0.243029'] 2011.348\n",
      "[1756, '0.036588', '44.48', '7.22', '0.243291'] 2013.598\n",
      "[1758, '0.036639', '44.29', '7.64', '0.242683'] 2015.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1760, '0.065457', '42.90', '8.11', '0.387610'] 2018.311\n",
      "[1762, '0.036460', '44.83', '7.42', '0.249134'] 2020.537\n",
      "[1764, '0.036685', '44.48', '8.24', '0.245996'] 2022.801\n",
      "[1766, '0.036562', '44.66', '6.82', '0.245765'] 2025.042\n",
      "[1768, '0.036525', '44.48', '6.73', '0.245067'] 2027.262\n",
      "[1770, '0.065270', '42.90', '8.20', '0.393095'] 2029.705\n",
      "[1772, '0.036653', '44.44', '6.99', '0.243958'] 2031.946\n",
      "[1774, '0.036403', '44.42', '6.92', '0.243572'] 2034.244\n",
      "[1776, '0.036605', '44.72', '7.24', '0.245386'] 2036.508\n",
      "[1778, '0.036527', '44.61', '6.96', '0.243288'] 2038.724\n",
      "[1780, '0.065357', '42.84', '8.09', '0.392298'] 2041.126\n",
      "[1782, '0.036562', '44.33', '7.25', '0.243190'] 2043.358\n",
      "[1784, '0.036519', '44.32', '7.48', '0.243343'] 2045.658\n",
      "[1786, '0.036399', '44.56', '7.15', '0.245449'] 2047.844\n",
      "[1788, '0.036448', '44.44', '7.16', '0.244655'] 2050.139\n",
      "[1790, '0.064905', '42.67', '7.90', '0.381668'] 2052.566\n",
      "[1792, '0.036474', '44.41', '6.80', '0.243760'] 2054.734\n",
      "[1794, '0.036847', '44.59', '7.75', '0.247393'] 2057.041\n",
      "[1796, '0.036401', '44.59', '7.93', '0.247048'] 2059.332\n",
      "[1798, '0.036486', '44.43', '7.08', '0.244094'] 2061.597\n",
      "[1800, '0.064919', '42.75', '7.63', '0.381063'] 2064.084\n",
      "[1802, '0.036568', '44.43', '7.75', '0.243912'] 2066.324\n",
      "[1804, '0.036362', '44.37', '6.83', '0.243299'] 2068.522\n",
      "[1806, '0.036440', '44.42', '7.19', '0.243456'] 2070.774\n",
      "[1808, '0.036733', '44.61', '8.02', '0.247580'] 2073.054\n",
      "[1810, '0.065374', '43.00', '7.99', '0.390052'] 2075.515\n",
      "[1812, '0.036325', '44.31', '7.24', '0.242359'] 2077.723\n",
      "[1814, '0.036586', '44.31', '7.44', '0.243047'] 2080.017\n",
      "[1816, '0.036347', '44.37', '7.01', '0.242818'] 2082.221\n",
      "[1818, '0.036269', '44.37', '6.82', '0.242715'] 2084.451\n",
      "[1820, '0.065486', '42.88', '8.48', '0.400118'] 2086.833\n",
      "[1822, '0.036218', '44.46', '7.22', '0.244719'] 2089.042\n",
      "[1824, '0.036537', '44.25', '7.62', '0.241568'] 2091.268\n",
      "[1826, '0.036323', '44.38', '7.18', '0.243318'] 2093.549\n",
      "[1828, '0.036222', '44.44', '6.85', '0.243423'] 2095.824\n",
      "[1830, '0.064899', '42.73', '8.02', '0.384330'] 2098.281\n",
      "[1832, '0.036388', '44.32', '7.09', '0.242701'] 2100.525\n",
      "[1834, '0.036282', '44.39', '7.40', '0.244712'] 2102.790\n",
      "[1836, '0.036233', '44.48', '6.83', '0.244225'] 2105.056\n",
      "[1838, '0.036344', '44.24', '7.31', '0.241915'] 2107.302\n",
      "[1840, '0.064773', '42.62', '7.84', '0.378636'] 2109.685\n",
      "[1842, '0.036559', '44.30', '7.48', '0.243145'] 2111.908\n",
      "[1844, '0.036458', '44.36', '7.65', '0.243418'] 2114.193\n",
      "[1846, '0.036372', '44.47', '7.44', '0.244751'] 2116.508\n",
      "[1848, '0.036355', '44.45', '7.79', '0.244709'] 2118.773\n",
      "[1850, '0.064922', '42.60', '7.66', '0.382911'] 2121.237\n",
      "[1852, '0.036584', '44.64', '7.65', '0.246881'] 2123.449\n",
      "[1854, '0.036722', '44.49', '7.66', '0.246420'] 2125.716\n",
      "[1856, '0.036179', '44.34', '7.41', '0.242610'] 2128.002\n",
      "[1858, '0.036354', '44.17', '7.20', '0.241611'] 2130.305\n",
      "[1860, '0.064801', '42.59', '8.15', '0.380879'] 2132.744\n",
      "[1862, '0.036340', '44.29', '7.79', '0.243863'] 2135.030\n",
      "[1864, '0.036104', '44.52', '6.86', '0.244025'] 2137.301\n",
      "[1866, '0.036362', '44.58', '7.10', '0.246065'] 2139.497\n",
      "[1868, '0.036168', '44.44', '6.87', '0.242124'] 2141.755\n",
      "[1870, '0.064894', '42.73', '7.83', '0.386566'] 2144.266\n",
      "[1872, '0.036319', '44.23', '7.13', '0.241995'] 2146.497\n",
      "[1874, '0.036317', '44.30', '7.16', '0.242157'] 2148.845\n",
      "[1876, '0.036198', '44.30', '6.80', '0.242523'] 2151.121\n",
      "[1878, '0.036262', '44.29', '7.45', '0.242450'] 2153.421\n",
      "[1880, '0.065247', '42.80', '7.77', '0.391351'] 2155.883\n",
      "[1882, '0.036164', '44.37', '7.03', '0.242338'] 2158.116\n",
      "[1884, '0.036213', '44.19', '7.41', '0.242122'] 2160.380\n",
      "[1886, '0.036158', '44.25', '6.72', '0.241672'] 2162.656\n",
      "[1888, '0.036320', '44.73', '6.81', '0.247129'] 2164.921\n",
      "[1890, '0.065301', '42.81', '8.42', '0.388406'] 2167.252\n",
      "[1892, '0.036175', '44.21', '7.86', '0.241895'] 2169.478\n",
      "[1894, '0.036281', '44.35', '6.88', '0.242278'] 2171.705\n",
      "[1896, '0.036218', '44.50', '6.87', '0.244495'] 2173.964\n",
      "[1898, '0.036200', '44.11', '7.00', '0.240173'] 2176.163\n",
      "[1900, '0.065179', '42.86', '8.14', '0.393777'] 2178.554\n",
      "[1902, '0.036258', '44.16', '7.50', '0.241015'] 2180.762\n",
      "[1904, '0.036304', '44.14', '7.68', '0.241073'] 2183.054\n",
      "[1906, '0.036316', '44.19', '7.09', '0.241750'] 2185.183\n",
      "[1908, '0.036120', '44.34', '6.73', '0.241746'] 2187.489\n",
      "[1910, '0.064973', '42.83', '7.98', '0.390757'] 2189.924\n",
      "[1912, '0.036188', '44.28', '6.87', '0.241260'] 2192.248\n",
      "[1914, '0.036503', '44.29', '7.67', '0.243161'] 2194.514\n",
      "[1916, '0.036144', '44.27', '7.23', '0.242802'] 2196.763\n",
      "[1918, '0.036219', '44.21', '7.12', '0.242085'] 2199.047\n",
      "[1920, '0.064759', '42.65', '7.71', '0.385580'] 2201.517\n",
      "[1922, '0.036059', '44.56', '6.96', '0.245370'] 2203.789\n",
      "[1924, '0.036077', '44.20', '7.18', '0.241219'] 2206.130\n",
      "[1926, '0.036328', '44.47', '6.86', '0.242734'] 2208.433\n",
      "[1928, '0.036061', '44.65', '6.87', '0.247867'] 2210.691\n",
      "[1930, '0.065262', '43.10', '8.14', '0.389990'] 2213.132\n",
      "[1932, '0.036255', '44.13', '7.43', '0.241292'] 2215.357\n",
      "[1934, '0.035990', '44.23', '6.64', '0.241024'] 2217.630\n",
      "[1936, '0.036103', '44.27', '6.68', '0.241694'] 2219.891\n",
      "[1938, '0.036418', '44.20', '7.50', '0.242378'] 2222.207\n",
      "[1940, '0.064769', '42.58', '7.84', '0.380691'] 2224.692\n",
      "[1942, '0.035994', '44.27', '6.78', '0.240487'] 2226.962\n",
      "[1944, '0.036226', '44.69', '7.28', '0.244834'] 2229.235\n",
      "[1946, '0.036152', '44.13', '7.28', '0.241101'] 2231.457\n",
      "[1948, '0.036100', '44.76', '7.11', '0.247727'] 2233.709\n",
      "[1950, '0.064887', '42.72', '8.32', '0.385645'] 2236.147\n",
      "[1952, '0.036035', '44.47', '6.67', '0.243564'] 2238.392\n",
      "[1954, '0.036040', '44.20', '6.92', '0.241455'] 2240.615\n",
      "[1956, '0.036040', '44.16', '7.01', '0.240560'] 2242.760\n",
      "[1958, '0.036039', '44.17', '6.72', '0.240965'] 2245.006\n",
      "[1960, '0.064865', '42.68', '7.92', '0.385094'] 2247.446\n",
      "[1962, '0.035935', '44.26', '6.72', '0.240276'] 2249.757\n",
      "[1964, '0.036061', '44.06', '7.00', '0.239718'] 2252.017\n",
      "[1966, '0.036231', '44.48', '8.95', '0.248447'] 2254.245\n",
      "[1968, '0.035956', '44.44', '7.01', '0.244077'] 2256.457\n",
      "[1970, '0.065244', '43.03', '8.11', '0.393026'] 2258.882\n",
      "[1972, '0.035980', '44.19', '6.73', '0.240426'] 2261.122\n",
      "[1974, '0.036077', '44.48', '6.82', '0.242652'] 2263.371\n",
      "[1976, '0.036062', '44.05', '7.74', '0.240952'] 2265.585\n",
      "[1978, '0.036027', '44.18', '6.69', '0.240362'] 2267.825\n",
      "[1980, '0.065176', '42.66', '8.18', '0.392372'] 2270.283\n",
      "[1982, '0.036145', '44.19', '7.44', '0.241874'] 2272.530\n",
      "[1984, '0.036079', '44.23', '6.96', '0.241039'] 2274.855\n",
      "[1986, '0.035907', '44.17', '7.57', '0.240432'] 2277.127\n",
      "[1988, '0.036113', '44.31', '7.33', '0.245848'] 2279.394\n",
      "[1990, '0.065671', '43.01', '9.06', '0.405756'] 2281.794\n",
      "[1992, '0.035802', '44.20', '6.82', '0.240858'] 2284.089\n",
      "[1994, '0.036048', '44.51', '7.10', '0.244870'] 2286.356\n",
      "[1996, '0.036372', '44.72', '8.89', '0.250839'] 2288.562\n",
      "[1998, '0.036755', '44.37', '8.63', '0.245753'] 2290.819\n",
      "[2000, '0.064469', '42.49', '7.58', '0.377596'] 2293.241\n",
      "[2002, '0.036114', '44.25', '6.92', '0.241098'] 2295.402\n",
      "[2004, '0.036109', '44.28', '6.97', '0.241423'] 2297.635\n",
      "[2006, '0.035968', '44.16', '7.03', '0.240590'] 2299.899\n",
      "[2008, '0.035910', '44.06', '6.85', '0.239384'] 2302.108\n",
      "[2010, '0.064345', '42.48', '7.72', '0.378333'] 2304.543\n",
      "[2012, '0.035820', '44.60', '7.35', '0.247783'] 2306.792\n",
      "[2014, '0.035853', '44.12', '6.62', '0.240169'] 2309.035\n",
      "[2016, '0.035877', '44.10', '6.75', '0.239906'] 2311.273\n",
      "[2018, '0.035852', '44.06', '6.84', '0.239797'] 2313.492\n",
      "[2020, '0.065486', '43.24', '8.58', '0.400495'] 2315.922\n",
      "[2022, '0.035734', '44.16', '7.00', '0.239856'] 2318.153\n",
      "[2024, '0.035897', '44.12', '7.12', '0.240275'] 2320.374\n",
      "[2026, '0.035752', '44.18', '6.55', '0.240253'] 2322.611\n",
      "[2028, '0.035938', '44.23', '6.87', '0.240972'] 2324.825\n",
      "[2030, '0.065192', '42.77', '8.13', '0.393660'] 2327.247\n",
      "[2032, '0.035904', '44.01', '7.17', '0.239493'] 2329.475\n",
      "[2034, '0.035914', '44.38', '7.08', '0.242502'] 2331.684\n",
      "[2036, '0.035994', '44.08', '6.94', '0.239898'] 2333.931\n",
      "[2038, '0.035778', '44.03', '7.18', '0.239084'] 2336.191\n",
      "[2040, '0.065168', '42.77', '8.14', '0.390964'] 2338.610\n",
      "[2042, '0.035826', '44.05', '7.20', '0.239337'] 2340.843\n",
      "[2044, '0.035784', '44.06', '6.70', '0.239668'] 2343.081\n",
      "[2046, '0.035864', '44.05', '7.05', '0.240033'] 2345.340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2048, '0.035840', '44.14', '6.76', '0.239699'] 2347.610\n",
      "[2050, '0.064447', '42.49', '7.36', '0.378206'] 2350.112\n",
      "[2052, '0.036082', '44.19', '7.26', '0.242944'] 2352.355\n",
      "[2054, '0.035701', '44.17', '6.84', '0.241314'] 2354.588\n",
      "[2056, '0.035813', '44.08', '6.64', '0.239431'] 2356.829\n",
      "[2058, '0.036353', '44.18', '8.17', '0.244013'] 2359.050\n",
      "[2060, '0.064705', '42.47', '7.95', '0.382346'] 2361.474\n",
      "[2062, '0.035812', '44.18', '6.42', '0.240578'] 2363.745\n",
      "[2064, '0.036253', '44.13', '8.39', '0.244035'] 2366.057\n",
      "[2066, '0.035976', '44.53', '7.05', '0.245015'] 2368.358\n",
      "[2068, '0.035913', '43.80', '7.72', '0.237992'] 2370.610\n",
      "[2070, '0.065004', '42.78', '7.93', '0.382045'] 2373.066\n",
      "[2072, '0.035952', '44.26', '7.48', '0.242816'] 2375.315\n",
      "[2074, '0.035935', '44.55', '7.05', '0.244715'] 2377.578\n",
      "[2076, '0.035867', '44.63', '7.12', '0.245116'] 2379.812\n",
      "[2078, '0.035946', '43.92', '7.61', '0.238480'] 2382.077\n",
      "[2080, '0.064456', '42.72', '7.83', '0.379813'] 2384.515\n",
      "[2082, '0.035928', '44.21', '7.16', '0.241905'] 2386.731\n",
      "[2084, '0.036025', '44.13', '7.58', '0.242967'] 2389.015\n",
      "[2086, '0.036120', '44.09', '7.86', '0.240912'] 2391.326\n",
      "[2088, '0.035753', '44.07', '7.06', '0.239279'] 2393.601\n",
      "[2090, '0.065369', '42.76', '9.11', '0.396712'] 2396.097\n",
      "[2092, '0.035632', '44.02', '6.75', '0.238836'] 2398.301\n",
      "[2094, '0.035874', '44.13', '6.49', '0.240266'] 2400.518\n",
      "[2096, '0.035730', '44.25', '6.65', '0.240278'] 2402.759\n",
      "[2098, '0.035708', '43.94', '6.86', '0.238283'] 2405.011\n",
      "[2100, '0.065017', '42.61', '8.11', '0.393510'] 2407.442\n",
      "[2102, '0.035813', '43.92', '7.02', '0.238327'] 2409.725\n",
      "[2104, '0.036047', '44.21', '7.33', '0.242481'] 2411.992\n",
      "[2106, '0.035846', '44.41', '7.02', '0.242695'] 2414.253\n",
      "[2108, '0.035700', '44.03', '6.64', '0.238776'] 2416.498\n",
      "[2110, '0.064727', '42.37', '7.98', '0.378138'] 2418.945\n",
      "[2112, '0.035754', '44.05', '6.86', '0.240263'] 2421.110\n",
      "[2114, '0.035825', '44.16', '7.62', '0.241021'] 2423.420\n",
      "[2116, '0.035737', '43.92', '6.98', '0.238523'] 2425.698\n",
      "[2118, '0.035780', '43.91', '6.69', '0.237323'] 2427.968\n",
      "[2120, '0.064700', '42.61', '7.52', '0.381004'] 2430.381\n",
      "[2122, '0.035924', '44.08', '7.65', '0.241086'] 2432.589\n",
      "[2124, '0.035868', '44.01', '6.55', '0.238243'] 2434.810\n",
      "[2126, '0.035595', '44.10', '6.76', '0.240078'] 2437.048\n",
      "[2128, '0.035813', '43.97', '7.56', '0.239821'] 2439.338\n",
      "[2130, '0.064551', '42.31', '7.77', '0.377558'] 2441.782\n",
      "[2132, '0.035705', '44.09', '6.59', '0.238377'] 2444.045\n",
      "[2134, '0.035649', '43.84', '6.92', '0.236892'] 2446.274\n",
      "[2136, '0.035949', '44.11', '6.92', '0.239926'] 2448.522\n",
      "[2138, '0.035872', '44.07', '6.93', '0.240372'] 2450.740\n",
      "[2140, '0.064568', '42.39', '7.82', '0.385820'] 2453.231\n",
      "[2142, '0.035642', '43.89', '7.24', '0.238140'] 2455.502\n",
      "[2144, '0.035913', '43.87', '7.94', '0.239182'] 2457.772\n",
      "[2146, '0.035737', '43.90', '7.20', '0.238287'] 2460.025\n",
      "[2148, '0.035481', '44.25', '6.72', '0.243261'] 2462.267\n",
      "[2150, '0.064105', '42.44', '7.41', '0.371465'] 2464.736\n",
      "[2152, '0.035634', '44.06', '7.11', '0.239166'] 2466.987\n",
      "[2154, '0.035817', '43.97', '7.41', '0.240059'] 2469.247\n",
      "[2156, '0.035653', '44.20', '6.76', '0.240294'] 2471.509\n",
      "[2158, '0.035851', '43.95', '6.72', '0.237171'] 2473.763\n",
      "[2160, '0.065095', '42.70', '8.21', '0.389316'] 2476.216\n",
      "[2162, '0.035757', '44.26', '7.50', '0.242937'] 2478.465\n",
      "[2164, '0.035468', '44.08', '6.59', '0.238447'] 2480.725\n",
      "[2166, '0.035705', '43.89', '6.89', '0.237985'] 2482.955\n",
      "[2168, '0.035755', '44.17', '6.79', '0.240635'] 2485.161\n",
      "[2170, '0.065054', '42.45', '7.81', '0.388660'] 2487.631\n",
      "[2172, '0.035588', '43.95', '6.72', '0.238874'] 2489.890\n",
      "[2174, '0.035596', '44.01', '7.51', '0.239301'] 2492.207\n",
      "[2176, '0.035700', '44.16', '6.91', '0.240048'] 2494.514\n",
      "[2178, '0.035521', '43.91', '6.56', '0.237549'] 2496.758\n",
      "[2180, '0.064615', '42.33', '7.89', '0.383236'] 2499.192\n",
      "[2182, '0.035492', '44.16', '6.57', '0.239162'] 2501.477\n",
      "[2184, '0.035567', '44.26', '7.23', '0.243290'] 2503.709\n",
      "[2186, '0.035559', '43.96', '6.77', '0.237930'] 2505.952\n",
      "[2188, '0.035523', '43.86', '6.61', '0.237293'] 2508.154\n",
      "[2190, '0.064529', '42.35', '7.57', '0.382261'] 2510.588\n",
      "[2192, '0.035737', '43.90', '7.53', '0.239678'] 2512.836\n",
      "[2194, '0.035725', '43.94', '8.04', '0.239838'] 2515.092\n",
      "[2196, '0.035556', '43.96', '6.65', '0.238409'] 2517.312\n",
      "[2198, '0.035534', '43.91', '7.19', '0.237956'] 2519.516\n",
      "[2200, '0.065005', '42.73', '8.39', '0.393754'] 2521.939\n",
      "[2202, '0.035560', '43.83', '6.66', '0.237119'] 2524.195\n",
      "[2204, '0.035727', '44.12', '7.10', '0.240501'] 2526.410\n",
      "[2206, '0.035568', '44.15', '7.30', '0.241184'] 2528.590\n",
      "[2208, '0.035674', '44.07', '7.09', '0.240700'] 2530.841\n",
      "[2210, '0.064481', '42.24', '7.88', '0.375212'] 2533.294\n",
      "[2212, '0.035365', '43.88', '6.78', '0.237478'] 2535.541\n",
      "[2214, '0.035632', '43.89', '6.94', '0.238006'] 2537.831\n",
      "[2216, '0.035413', '43.96', '6.73', '0.237522'] 2540.074\n",
      "[2218, '0.035551', '44.27', '6.82', '0.240322'] 2542.310\n",
      "[2220, '0.064815', '42.45', '8.01', '0.388330'] 2544.758\n",
      "[2222, '0.035616', '44.03', '6.71', '0.240084'] 2547.046\n",
      "[2224, '0.035469', '43.84', '6.60', '0.237077'] 2549.384\n",
      "[2226, '0.035533', '44.14', '6.52', '0.240047'] 2551.642\n",
      "[2228, '0.035417', '44.04', '6.82', '0.240219'] 2553.878\n",
      "[2230, '0.065148', '42.48', '8.59', '0.391228'] 2556.317\n",
      "[2232, '0.035387', '44.04', '7.27', '0.240081'] 2558.571\n",
      "[2234, '0.035760', '43.85', '7.72', '0.237938'] 2560.848\n",
      "[2236, '0.035319', '43.93', '6.64', '0.237638'] 2563.097\n",
      "[2238, '0.035412', '43.95', '6.46', '0.237923'] 2565.321\n",
      "[2240, '0.063978', '42.15', '7.80', '0.372420'] 2567.759\n",
      "[2242, '0.035446', '43.75', '6.70', '0.236259'] 2569.982\n",
      "[2244, '0.035547', '43.90', '6.45', '0.237082'] 2572.207\n",
      "[2246, '0.035562', '43.79', '7.41', '0.238745'] 2574.438\n",
      "[2248, '0.035552', '44.12', '6.75', '0.238840'] 2576.705\n",
      "[2250, '0.064266', '42.18', '7.89', '0.373879'] 2579.112\n",
      "[2252, '0.035400', '43.77', '6.40', '0.236105'] 2581.369\n",
      "[2254, '0.035422', '43.76', '6.51', '0.235983'] 2583.632\n",
      "[2256, '0.035408', '43.82', '6.48', '0.237278'] 2585.937\n",
      "[2258, '0.035410', '43.83', '6.48', '0.236700'] 2588.185\n",
      "[2260, '0.064608', '42.30', '8.26', '0.383424'] 2590.650\n",
      "[2262, '0.035381', '43.81', '6.50', '0.236812'] 2592.825\n",
      "[2264, '0.035365', '43.93', '6.49', '0.237352'] 2595.059\n",
      "[2266, '0.035353', '43.84', '6.86', '0.237620'] 2597.305\n",
      "[2268, '0.035362', '43.71', '6.47', '0.236252'] 2599.511\n",
      "[2270, '0.064160', '42.13', '8.11', '0.375822'] 2601.993\n",
      "[2272, '0.035259', '43.86', '6.99', '0.237435'] 2604.201\n",
      "[2274, '0.035398', '43.75', '6.61', '0.235844'] 2606.450\n",
      "[2276, '0.035361', '43.71', '7.01', '0.236707'] 2608.697\n",
      "[2278, '0.035420', '43.76', '7.32', '0.237991'] 2611.024\n",
      "[2280, '0.064219', '42.26', '7.38', '0.378829'] 2613.554\n",
      "[2282, '0.035114', '43.84', '6.73', '0.237183'] 2615.793\n",
      "[2284, '0.035574', '43.74', '7.35', '0.237162'] 2618.051\n",
      "[2286, '0.035391', '43.86', '6.90', '0.237230'] 2620.223\n",
      "[2288, '0.035448', '44.09', '7.40', '0.241446'] 2622.486\n",
      "[2290, '0.064534', '42.25', '8.30', '0.382749'] 2624.915\n",
      "[2292, '0.035331', '43.94', '6.47', '0.237013'] 2627.138\n",
      "[2294, '0.035387', '43.90', '6.60', '0.237079'] 2629.398\n",
      "[2296, '0.035599', '43.78', '7.39', '0.236932'] 2631.664\n",
      "[2298, '0.035380', '44.04', '7.24', '0.241143'] 2633.948\n",
      "[2300, '0.064536', '42.21', '7.83', '0.383123'] 2636.373\n",
      "[2302, '0.035277', '43.79', '6.60', '0.235305'] 2638.609\n",
      "[2304, '0.035347', '43.95', '6.58', '0.238869'] 2640.860\n",
      "[2306, '0.035439', '43.79', '7.55', '0.238148'] 2643.175\n",
      "[2308, '0.035344', '43.70', '6.72', '0.235446'] 2645.404\n",
      "[2310, '0.064452', '42.27', '7.75', '0.384862'] 2647.884\n",
      "[2312, '0.035140', '43.90', '6.35', '0.236697'] 2650.136\n",
      "[2314, '0.035619', '43.84', '7.41', '0.239042'] 2652.356\n",
      "[2316, '0.035181', '43.81', '6.41', '0.235966'] 2654.600\n",
      "[2318, '0.035800', '44.67', '7.74', '0.248104'] 2656.841\n",
      "[2320, '0.065073', '42.62', '8.36', '0.397306'] 2659.308\n",
      "[2322, '0.035213', '43.85', '6.67', '0.236700'] 2661.450\n",
      "[2324, '0.035489', '43.99', '7.74', '0.239853'] 2663.687\n",
      "[2326, '0.035269', '43.84', '7.05', '0.237509'] 2665.926\n",
      "[2328, '0.035291', '43.77', '6.76', '0.236174'] 2668.175\n",
      "[2330, '0.065183', '42.44', '8.57', '0.397458'] 2670.609\n",
      "[2332, '0.035167', '43.86', '6.64', '0.237917'] 2672.859\n",
      "[2334, '0.035139', '43.72', '6.82', '0.235599'] 2675.079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2336, '0.035321', '43.66', '6.88', '0.235221'] 2677.305\n",
      "[2338, '0.035164', '43.76', '6.51', '0.235762'] 2679.536\n",
      "[2340, '0.065307', '42.60', '8.93', '0.404162'] 2681.990\n",
      "[2342, '0.035233', '43.63', '6.82', '0.235113'] 2684.230\n",
      "[2344, '0.035477', '43.85', '7.21', '0.239113'] 2686.494\n",
      "[2346, '0.035343', '44.17', '6.51', '0.239439'] 2688.740\n",
      "[2348, '0.035032', '43.76', '6.53', '0.235960'] 2691.010\n",
      "[2350, '0.064235', '42.19', '7.36', '0.378525'] 2693.506\n",
      "[2352, '0.035244', '43.76', '6.41', '0.235754'] 2695.712\n",
      "[2354, '0.035494', '44.04', '6.70', '0.241814'] 2697.939\n",
      "[2356, '0.035081', '43.78', '7.08', '0.236513'] 2700.156\n",
      "[2358, '0.035316', '43.64', '6.42', '0.235407'] 2702.457\n",
      "[2360, '0.064389', '42.29', '7.63', '0.384013'] 2704.904\n",
      "[2362, '0.035264', '43.98', '6.56', '0.238283'] 2707.131\n",
      "[2364, '0.035447', '43.87', '7.21', '0.238591'] 2709.352\n",
      "[2366, '0.035322', '43.76', '6.45', '0.235638'] 2711.609\n",
      "[2368, '0.035322', '43.58', '6.69', '0.233293'] 2713.839\n",
      "[2370, '0.064600', '42.32', '7.98', '0.389237'] 2716.304\n",
      "[2372, '0.035199', '43.68', '7.06', '0.236881'] 2718.581\n",
      "[2374, '0.035223', '43.81', '6.52', '0.236557'] 2720.825\n",
      "[2376, '0.035155', '43.83', '6.80', '0.238119'] 2723.062\n",
      "[2378, '0.035160', '43.71', '6.65', '0.235094'] 2725.318\n",
      "[2380, '0.064964', '42.37', '8.39', '0.391994'] 2727.738\n",
      "[2382, '0.035119', '43.75', '6.52', '0.235148'] 2730.001\n",
      "[2384, '0.035320', '43.71', '6.48', '0.236427'] 2732.266\n",
      "[2386, '0.035405', '43.90', '7.67', '0.238070'] 2734.542\n",
      "[2388, '0.034987', '43.69', '6.74', '0.234660'] 2736.800\n",
      "[2390, '0.064381', '42.10', '7.97', '0.383844'] 2739.229\n",
      "[2392, '0.035190', '43.66', '6.57', '0.235607'] 2741.421\n",
      "[2394, '0.035070', '44.03', '6.75', '0.239784'] 2743.700\n",
      "[2396, '0.035344', '43.72', '7.86', '0.237214'] 2745.946\n",
      "[2398, '0.035112', '43.62', '7.36', '0.234653'] 2748.197\n",
      "[2400, '0.063920', '42.06', '7.44', '0.375347'] 2750.625\n",
      "[2402, '0.035471', '43.90', '7.79', '0.240828'] 2752.800\n",
      "[2404, '0.034955', '43.83', '6.94', '0.236572'] 2755.025\n",
      "[2406, '0.035474', '43.76', '7.93', '0.237443'] 2757.262\n",
      "[2408, '0.035078', '43.93', '7.11', '0.238993'] 2759.482\n",
      "[2410, '0.064778', '42.29', '8.63', '0.383375'] 2761.967\n",
      "[2412, '0.035367', '43.50', '7.96', '0.233790'] 2764.251\n",
      "[2414, '0.034907', '43.79', '6.46', '0.235905'] 2766.564\n",
      "[2416, '0.035135', '44.02', '7.01', '0.236989'] 2768.851\n",
      "[2418, '0.035087', '43.62', '6.83', '0.234178'] 2771.122\n",
      "[2420, '0.064237', '42.23', '8.68', '0.383822'] 2773.566\n",
      "[2422, '0.035054', '43.85', '6.71', '0.236127'] 2775.785\n",
      "[2424, '0.035295', '43.91', '7.54', '0.239741'] 2778.062\n",
      "[2426, '0.035079', '43.87', '6.50', '0.235579'] 2780.314\n",
      "[2428, '0.035159', '43.57', '6.97', '0.234949'] 2782.582\n",
      "[2430, '0.064288', '42.15', '7.92', '0.381440'] 2784.947\n",
      "[2432, '0.035168', '43.54', '6.73', '0.233779'] 2787.207\n",
      "[2434, '0.035078', '43.63', '6.61', '0.234491'] 2789.458\n",
      "[2436, '0.035018', '43.82', '6.73', '0.237200'] 2791.679\n",
      "[2438, '0.035074', '43.62', '6.40', '0.234350'] 2794.028\n",
      "[2440, '0.064083', '41.90', '7.66', '0.374265'] 2796.446\n",
      "[2442, '0.034997', '43.82', '6.43', '0.236669'] 2798.690\n",
      "[2444, '0.034975', '43.61', '6.47', '0.233770'] 2800.934\n",
      "[2446, '0.035102', '43.49', '6.73', '0.233315'] 2803.186\n",
      "[2448, '0.035143', '43.53', '7.14', '0.234817'] 2805.484\n",
      "[2450, '0.064119', '41.96', '7.44', '0.371965'] 2807.927\n",
      "[2452, '0.034940', '43.73', '6.45', '0.235414'] 2810.125\n",
      "[2454, '0.035067', '43.88', '6.33', '0.236426'] 2812.359\n",
      "[2456, '0.034873', '43.67', '6.58', '0.234955'] 2814.572\n",
      "[2458, '0.035060', '43.49', '6.85', '0.234146'] 2816.786\n",
      "[2460, '0.064270', '42.16', '8.18', '0.386875'] 2819.342\n",
      "[2462, '0.035180', '43.63', '7.14', '0.234970'] 2821.619\n",
      "[2464, '0.034854', '43.75', '6.69', '0.236145'] 2823.876\n",
      "[2466, '0.034936', '43.57', '6.58', '0.233510'] 2826.018\n",
      "[2468, '0.035431', '44.15', '7.21', '0.243140'] 2828.295\n",
      "[2470, '0.064857', '42.37', '9.01', '0.390966'] 2830.761\n",
      "[2472, '0.034897', '43.77', '6.66', '0.235474'] 2833.000\n",
      "[2474, '0.035008', '43.47', '6.78', '0.233022'] 2835.213\n",
      "[2476, '0.034938', '43.59', '6.68', '0.234350'] 2837.377\n",
      "[2478, '0.034954', '43.61', '6.46', '0.233618'] 2839.653\n",
      "[2480, '0.064547', '42.07', '8.43', '0.390672'] 2842.110\n",
      "[2482, '0.035056', '43.98', '6.64', '0.238008'] 2844.347\n",
      "[2484, '0.034863', '43.50', '6.64', '0.234292'] 2846.585\n",
      "[2486, '0.035131', '43.55', '7.11', '0.234423'] 2848.831\n",
      "[2488, '0.034898', '43.89', '6.58', '0.236659'] 2851.114\n",
      "[2490, '0.063776', '41.94', '7.39', '0.370423'] 2853.574\n",
      "[2492, '0.034986', '43.74', '6.59', '0.235910'] 2855.834\n",
      "[2494, '0.034915', '43.61', '6.66', '0.235453'] 2858.091\n",
      "[2496, '0.035203', '43.81', '7.35', '0.237434'] 2860.332\n",
      "[2498, '0.035155', '43.85', '8.07', '0.240049'] 2862.630\n"
     ]
    }
   ],
   "source": [
    "PATH = 'checkpoint/finenet_9.pth' \n",
    "import numpy as np \n",
    "\n",
    "train_loader = DataLoader(datasetTrain, batch_size=1, shuffle=True,num_workers=2)\n",
    "test_loader = DataLoader(datasetTest, batch_size=1, shuffle=False,num_workers=2)\n",
    "\n",
    "no_training = len(train_loader) \n",
    "no_testing = len(test_loader) \n",
    "\n",
    "model.train()\n",
    "best_loss = 200 \n",
    "t = time.time() \n",
    "count = 0 \n",
    "val = 14688000\n",
    "for epoch in range(2500):\n",
    "    total_loss1 = 0 \n",
    "    total_loss2 = 0 \n",
    "    theta = [] \n",
    "    for indx, data in enumerate(train_loader):\n",
    "        data_gpu = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "     #   print(data_gpu.y.shape)\n",
    "\n",
    "        out, loss1, beta = model(data_gpu)\n",
    "    #    out = data_gpu.x + out  \n",
    "   #     out = qmul(data_gpu.x, out) \n",
    "      #  out = F.normalize(out, p=2, dim=1) \n",
    "     #   print(out.shape)\n",
    "      #  loss1 = qmul(inv_q(data_gpu.edge_attr), edge_out)  \n",
    "      #  out = node_model(out, data_gpu.batch)\n",
    "      #  out = F.normalize(out, p=2, dim=1)\n",
    "        out = qmul(inv_q(data_gpu.y), out) \n",
    "      #  loss1 = F.normalize(loss1, p=2, dim=1) \n",
    "        out = F.normalize(out, p=2, dim=1) \n",
    "\n",
    "    # F.smooth_l1_loss(10*edge_out, 10*data_gpu.edge_attr, size_average=None)  \n",
    "      #  loss2 = F.mse_loss(out, data_gpu.y, size_average=None) \n",
    "   #    loss1 = loss1[:, 1:].abs().sum() #torch.nn.MSELoss(out, data_gpu.y)\n",
    "        loss2 = smooth_l1_loss(out[:, 0:]) \n",
    " \n",
    "      #  loss2 = out[:, 1:].pow(2).sum() #(out - data_gpu.y).pow(2).sum() #torch.nn.MSELoss(out, data_gpu.y)\n",
    "        loss = loss1 + 0.25*loss2 \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      #  print([indx, loss.item()])\n",
    "     #   time.sleep(0.05)\n",
    "        count = count + 1\n",
    "        if epoch % 2 == 0:\n",
    "            total_loss1 = total_loss1 + loss1.item() \n",
    "            total_loss2 = total_loss2 + loss2.item()\n",
    "          #  out = qmul(inv_q(data_gpu.y), data_gpu.xt) \n",
    "            val2 = out.data.cpu().numpy()\n",
    "            theta = np.concatenate((theta, 2.0*np.arccos(np.abs(val2[:, 0]))*180.0/np.pi ))\n",
    "    total_loss1 = total_loss1/no_training\n",
    "    total_loss2 = total_loss2/no_training\n",
    "    if epoch % 10 == 0:\n",
    "        total_loss1 = 0 \n",
    "        total_loss2 = 0 \n",
    "        for data in test_loader: \n",
    "            data_gpu = data.to(device)\n",
    "            out, loss1, beta = model(data_gpu)\n",
    "            out = qmul(inv_q(data_gpu.y), out) \n",
    "            out = F.normalize(out, p=2, dim=1) \n",
    "            loss2 = smooth_l1_loss(out[:, 0:]) \n",
    "            total_loss1 = total_loss1 + loss1.item() \n",
    "            total_loss2 = total_loss2 + loss2.item()\n",
    "          #  out = qmul(inv_q(data_gpu.y), data_gpu.xt) \n",
    "            val2 = out.data.cpu().numpy()\n",
    "            theta = np.concatenate((theta, 2.0*np.arccos(np.abs(val2[:, 0]))*180.0/np.pi ))\n",
    "        # print([count, total_loss1/no_training, total_loss2/no_training], time.time() - t) \n",
    "        total_loss1 = total_loss1/no_testing\n",
    "        total_loss2 = total_loss2/no_testing\n",
    "    if epoch % 2 == 0: \n",
    "        print([epoch, \"{0:.6f}\".format(total_loss1), \"{0:.2f}\".format(np.mean(theta)), \"{0:.2f}\".format(np.median(theta)), \"{0:.6f}\".format(total_loss2)], \"{0:.3f}\".format(time.time() - t))\n",
    "        if val > total_loss1/no_training : \n",
    "            val = total_loss1/no_training \n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, PATH) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[32.13338178016772, 15.474712371826172, 2.222583770751953]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import math \n",
    "import h5py\n",
    "import torch \n",
    "import time \n",
    "data_path = './' # os.getcwd() \n",
    "\n",
    "PATH = 'checkpoint/finenet_9.pth' \n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "model = Net().to(device) \n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "test_loader = DataLoader(datasetTest, batch_size=1, shuffle=False)\n",
    "#model = best_model \n",
    "#print(best_loss)\n",
    "#pred_rot = []\n",
    "model.eval()\n",
    "total_loss = 0 \n",
    "t = time.time() \n",
    "count = 0 \n",
    "hf = h5py.File(data_path+'data/neurora_9.h5', 'w')\n",
    "#hf = h5py.File(data_path+'data/pred_synthetic_rot_another.h5', 'w')\n",
    "theta = [] \n",
    "\n",
    "for data in test_loader: \n",
    "    data_gpu = data.to(device)\n",
    "    pred, out, beta = model(data_gpu)\n",
    "   # data_gpu.x = pred\n",
    "   # pred, out, beta = model(data_gpu)\n",
    "   # data_gpu.x = pred\n",
    "  #  pred, out, beta = model(data_gpu)\n",
    "  #  pred = qmul(data_gpu.x, pred) \n",
    "  #  pred = data_gpu.x + pred\n",
    "   # pred = F.normalize(pred, p=2, dim=1) \n",
    "  #  pred = node_model(pred, data_gpu.batch)\n",
    "    pred = F.normalize(pred, p=2, dim=1)\n",
    "        \n",
    "    out = qmul(inv_q(data_gpu.y), pred) \n",
    "  #  out = qmul(inv_q(data_gpu.y), data_gpu.xt) \n",
    "    out = F.normalize(out, p=2, dim=1) \n",
    "    \n",
    "    val2 = out.data.cpu().numpy()\n",
    "  #  print(val.size)\n",
    "    theta = np.concatenate((theta, 2.0*np.arccos(np.abs(val2[:, 0]))*180.0/np.pi )) \n",
    "    \n",
    "    loss = out[:, 1:].pow(2).sum() \n",
    " #   loss = (pred - data_gpu.y).pow(2).sum() \n",
    "    total_loss = total_loss + loss.item() \n",
    "    pred_rot = torch.cat([data_gpu.x, data_gpu.xt, pred, data_gpu.y], dim=1).data.cpu().numpy()\n",
    "    hf.create_dataset('/data/'+str(count+1), data=pred_rot)\n",
    "    count = count + 1 \n",
    "   # print([len(pred_rot), (time.time()-t)/len(pred_rot)])\n",
    "print(len(test_loader))\n",
    "hf.close()\n",
    "print([np.mean(theta), np.median(theta), (time.time() - t)/(test_loader.batch_size*len(test_loader))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
